{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow MNIST Classifier demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">⚠️ **Warning:** Some of the attacks in this demo, _deepfool_ and _CW_ in particular, are computationally expensive and will take a very long to complete if run using the CPUs found in a typical personal computer.\n",
    "> For this reason, it is highly recommended that you run these demos on a CUDA-compatible GPU.\n",
    "\n",
    "This notebook contains an end-to-end demostration of Dioptra that can be run on any modern laptop.\n",
    "Please see the [example README](README.md) for instructions on how to prepare your environment for running this example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we import the necessary Python modules and ensure the proper environment variables are set so that all the code blocks will work as expected,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import packages from the Python standard library\n",
    "import importlib.util\n",
    "import os\n",
    "import sys\n",
    "import pprint\n",
    "import time\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def register_python_source_file(module_name: str, filepath: Path) -> None:\n",
    "    \"\"\"Import a source file directly.\n",
    "\n",
    "    Args:\n",
    "        module_name: The module name to associate with the imported source file.\n",
    "        filepath: The path to the source file.\n",
    "\n",
    "    Notes:\n",
    "        Adapted from the following implementation in the Python documentation:\n",
    "        https://docs.python.org/3/library/importlib.html#importing-a-source-file-directly\n",
    "    \"\"\"\n",
    "    spec = importlib.util.spec_from_file_location(module_name, str(filepath))\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    sys.modules[module_name] = module\n",
    "    spec.loader.exec_module(module)\n",
    "\n",
    "\n",
    "# Filter out warning messages\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Experiment name\n",
    "EXPERIMENT_NAME = \"mnist_feature_squeezing\"\n",
    "\n",
    "# Default address for accessing the RESTful API service\n",
    "RESTAPI_ADDRESS = \"http://localhost:80\"\n",
    "\n",
    "# Set DIOPTRA_RESTAPI_URI variable if not defined, used to connect to RESTful API service\n",
    "if os.getenv(\"DIOPTRA_RESTAPI_URI\") is None:\n",
    "    os.environ[\"DIOPTRA_RESTAPI_URI\"] = RESTAPI_ADDRESS\n",
    "\n",
    "# Default address for accessing the MLFlow Tracking server\n",
    "MLFLOW_TRACKING_URI = \"http://localhost:35000\"\n",
    "\n",
    "# Set MLFLOW_TRACKING_URI variable, used to connect to MLFlow Tracking service\n",
    "if os.getenv(\"MLFLOW_TRACKING_URI\") is None:\n",
    "    os.environ[\"MLFLOW_TRACKING_URI\"] = MLFLOW_TRACKING_URI\n",
    "\n",
    "# Path to workflows archive\n",
    "WORKFLOWS_TAR_GZ = Path(\"workflows.tar.gz\")\n",
    "\n",
    "# Register the examples/scripts directory as a Python module\n",
    "register_python_source_file(\"scripts\", Path(\"..\", \"scripts\", \"__init__.py\"))\n",
    "\n",
    "from scripts.client import DioptraClient\n",
    "from scripts.utils import make_tar\n",
    "\n",
    "# Import third-party Python packages\n",
    "import numpy as np\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# Create random number generator\n",
    "rng = np.random.default_rng(54399264723942495723666216079516778448)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mnist_model = \"feature_squeezing_mnist_le_net\" \n",
    "mnist_shallow = \"feature_squeezing_mnist_shallow_net\"\n",
    "model_id = 1\n",
    "model_id_shallow = 1\n",
    "mnist_dataset_training = \"/dioptra/data/Mnist/training\"\n",
    "mnist_dataset_testing = \"/dioptra/data/Mnist/testing\"\n",
    "mlflow_queue = \"tensorflow_cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mlflow_run_id_is_not_known(response):\n",
    "    return response[\"mlflowRunId\"] is None and response[\"status\"] not in [\n",
    "        \"failed\",\n",
    "        \"finished\",\n",
    "    ]\n",
    "\n",
    "def print_response(jobtype, jobname, response):\n",
    "    print(f\"{jobtype} for job {jobname} submitted.\")\n",
    "    print(\"\")\n",
    "    pprint.pprint(response)\n",
    "    print(\"\")\n",
    "    \n",
    "def wait_for_job(response):\n",
    "    while mlflow_run_id_is_not_known(response):\n",
    "        time.sleep(1)\n",
    "        response = restapi_client.get_job_by_id(response[\"jobId\"]) \n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtained a copy of the MNIST dataset when we ran `download_data.py` script. If you have not done so already, see [How to Obtain Common Datasets](https://pages.nist.gov/dioptra/getting-started/acquiring-datasets.html).\n",
    "The training and testing images for the MNIST dataset are stored within the `/dioptra/data/Mnist` directory as PNG files that are organized into the following folder structure,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Mnist\n",
    "    ├── testing\n",
    "    │   ├── 0\n",
    "    │   ├── 1\n",
    "    │   ├── 2\n",
    "    │   ├── 3\n",
    "    │   ├── 4\n",
    "    │   ├── 5\n",
    "    │   ├── 6\n",
    "    │   ├── 7\n",
    "    │   ├── 8\n",
    "    │   └── 9\n",
    "    └── training\n",
    "        ├── 0\n",
    "        ├── 1\n",
    "        ├── 2\n",
    "        ├── 3\n",
    "        ├── 4\n",
    "        ├── 5\n",
    "        ├── 6\n",
    "        ├── 7\n",
    "        ├── 8\n",
    "        └── 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The subfolders under `training/` and `testing/` are the classification labels for the images in the dataset.\n",
    "This folder structure is a standardized way to encode the label information and many libraries can make use of it, including the Tensorflow library that we are using for this particular demo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit and run jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entrypoints that we will be running in this example are implemented in the Python source files under `src/` and the `src/MLproject` file.\n",
    "To run these entrypoints within Dioptra's architecture, we need to package those files up into an archive and submit it to the Dioptra RESTful API to create a new job.\n",
    "For convenience, we provide the `make_tar` helper function defined in `examples/scripts/utils.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "make_tar([\"src\"], WORKFLOWS_TAR_GZ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To connect with the endpoint, we will use a client class defined in the `examples/scripts/client.py` file that is able to connect with the Dioptra RESTful API using the HTTP protocol.\n",
    "We connect using the client below.\n",
    "The client uses the environment variable `DIOPTRA_RESTAPI_URI`, which we configured at the top of the notebook, to figure out how to connect to the Dioptra RESTful API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "restapi_client = DioptraClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to register an experiment under which to collect our job runs.\n",
    "The code below checks if the relevant experiment named `\"mnist\"` exists.\n",
    "If it does, then it just returns info about the experiment, if it doesn't, it then registers the new experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response_experiment = restapi_client.get_experiment_by_name(name=EXPERIMENT_NAME)\n",
    "\n",
    "if response_experiment is None or \"Not Found\" in response_experiment.get(\"message\", []):\n",
    "    response_experiment = restapi_client.register_experiment(name=EXPERIMENT_NAME)\n",
    "\n",
    "response_experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to train our model.\n",
    "Depending on the specs of your computer, training either the shallow net model or the LeNet-5 model on a CPU can take 10-20 minutes or longer to complete.\n",
    "If you are fortunate enough to have access to a dedicated GPU, then the training time will be much shorter.\n",
    "\n",
    "So that we do not start this code by accident, we are embedding the code in a text block instead of keeping it in an executable code block.\n",
    "**If you need to train one of the models, create a new code block and copy and paste the code into it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response_shallow_train = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"train\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            \"-P model_architecture=shallow_net\",\n",
    "            \"-P epochs=30\",\n",
    "            f\"-P register_model_name={mnist_shallow}\",\n",
    "            f\"-P training_dir={mnist_dataset_training}\",\n",
    "        ]\n",
    "    ),\n",
    "    queue=mlflow_queue,\n",
    ")\n",
    "\n",
    "print_response(\"Training\", \"shallow neural network\", response_shallow_train)\n",
    "\n",
    "response_le_net_train = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"train\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            \"-P model_architecture=le_net\",\n",
    "            \"-P epochs=30\",\n",
    "            f\"-P register_model_name={mnist_model}\",\n",
    "            f\"-P training_dir={mnist_dataset_training}\",\n",
    "        ]\n",
    "    ),\n",
    "    queue=mlflow_queue,\n",
    ")\n",
    "\n",
    "print_response(\"Training\", \"LeNet-5 neural network\", response_le_net_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block generates adversarial images on the MNIST dataset using the Fast Gradient Method attack and then attempts to classify the adversarial images.\n",
    "\n",
    "| parameter | type | description |\n",
    "| --- | --- | --- |\n",
    "| `eps` | _float_ | Attack step size. \\[default: 0.3\\] |\n",
    "| `eps_step` | _float_ | Step size of input variation for minimal perturbation computation. [default: 0.1] |\n",
    "| `targeted` | _bool_ | Indicates whether the attack is targeted (True) or untargeted (False). [default: False] |\n",
    "| `num_random_init` | _int_ | Number of random initializations within the epsilon ball. For ``random_init=0`` starting at the original input. [default: 0] |\n",
    "| `minimal` | _bool_ | Indicates if computing the minimal perturbation (True). If True, also define eps_step for the step size and eps for the maximum perturbation. [default: False] |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_fgm_le_net = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"fgm\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P model_name={mnist_model}\",\n",
    "            f\"-P data_dir={mnist_dataset_testing}\",\n",
    "            f\"-P model_version={model_id}\"\n",
    "        ]\n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    "    timeout=\"1h\"\n",
    "\n",
    ")\n",
    "\n",
    "print_response(\"Attack\", \"FGM\", response_fgm_le_net)\n",
    "response_fgm_le_net = wait_for_job(response_fgm_le_net)\n",
    "    \n",
    "response_infer = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"infer\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={response_fgm_le_net['mlflowRunId']}\",\n",
    "            f\"-P model_version={model_id}\",\n",
    "            f\"-P model_name={mnist_model}\",\n",
    "        ]\n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    "    depends_on=response_fgm_le_net[\"jobId\"]\n",
    ")\n",
    "    \n",
    "print(\"Dependent jobs submitted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block does the same as the previous block, but applies the feature squeezing defense between the attack and infer steps.\n",
    "This pre-processing defense compresses the images being classified by our neural network such that their color depth is reduced to a binary, monochrome pallete.\n",
    "The level of compression can be tuned by adjusting the bit_depth parameter below (use values between 1 (binary) and 8 (original image color depth) to tune the defense.\n",
    "\n",
    "**FGM parameters**\n",
    "\n",
    "| parameter | type | description |\n",
    "| --- | --- | --- |\n",
    "| `eps` | _float_ | Attack step size. \\[default: 0.3\\] |\n",
    "| `eps_step` | _float_ | Step size of input variation for minimal perturbation computation. [default: 0.1] |\n",
    "| `targeted` | _bool_ | Indicates whether the attack is targeted (True) or untargeted (False). [default: False] |\n",
    "| `num_random_init` | _int_ | Number of random initializations within the epsilon ball. For ``random_init=0`` starting at the original input. [default: 0] |\n",
    "| `minimal` | _bool_ | Indicates if computing the minimal perturbation (True). If True, also define eps_step for the step size and eps for the maximum perturbation. [default: False] |\n",
    "\n",
    "**Feature squeezing parameters**\n",
    "\n",
    "| parameter | type | description |\n",
    "| --- | --- | --- |\n",
    "| `bit_depth` | _int_ | An integer between 1-8 that defines the color depth of the squeezed image. [default: 8] |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_fgm_le_net = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"fgm\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P model_name={mnist_model}\",\n",
    "            f\"-P data_dir={mnist_dataset_testing}\",\n",
    "            f\"-P model_version={model_id}\"\n",
    "        ]\n",
    "\n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    "\n",
    ")\n",
    "\n",
    "print_response(\"Attack\", \"FGM\", response_fgm_le_net)\n",
    "response_fgm_le_net = wait_for_job(response_fgm_le_net)\n",
    "\n",
    "response_feature_squeeze = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"feature_squeeze\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={response_fgm_le_net['mlflowRunId']}\",\n",
    "            f\"-P model={mnist_model}/{model_id}\",\n",
    "            \"-P model_architecture=le_net\",\n",
    "            \"-P bit_depth=1\",\n",
    "            \"-P batch_size=32\"\n",
    "        ]\n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    "    depends_on=response_fgm_le_net[\"jobId\"],\n",
    "    timeout = \"1h\"\n",
    ")\n",
    "\n",
    "print_response(\"Defense\", \"Feature Squeezing\", response_feature_squeeze)\n",
    "response_feature_squeeze = wait_for_job(response_feature_squeeze)\n",
    "\n",
    "response_infer_defended = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"infer\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={response_feature_squeeze['mlflowRunId']}\",\n",
    "            f\"-P model_version={model_id}\",\n",
    "            f\"-P model_name={mnist_model}\",\n",
    "        ]\n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    "    depends_on=response_feature_squeeze[\"jobId\"]\n",
    ")\n",
    "    \n",
    "print(\"Dependent jobs submitted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block uses the carlini-wagner attack with the Linf distance metric to generate adversarial images and checks the model's accuracy against the attack.\n",
    "\n",
    "**Carlini Wagner Parameters**\n",
    "\n",
    "| parameter | type | description |\n",
    "| --- | --- | --- |\n",
    "| `targeted` | _bool_ | Indicates whether the attack is targeted (True) or untargeted (False). [default: False] |\n",
    "| `learning_rate` | _float_ | The initial learning rate for the attack algorithm. Smaller values produce better results but are slower to converge. [default: 0.01] |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_cw_le_net = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"cw_inf\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P model_name={mnist_shallow}\",\n",
    "            f\"-P model_version={model_id_shallow}\",\n",
    "            \"-P model_architecture=shallow_net\",\n",
    "            \"-P targeted=True\",\n",
    "            \"-P max_iter=10\",\n",
    "            \"-P confidence=0.0\",\n",
    "            f\"-P testing_dir={mnist_dataset_testing}\",\n",
    "            \"-P learning_rate=0.01\",\n",
    "            \"-P verbose=True\",\n",
    "            \"-P batch_size=32\"\n",
    "        ]\n",
    "\n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    "\n",
    ")\n",
    "\n",
    "print_response(\"Attack\", \"CW Inf\", response_cw_le_net)\n",
    "response_cw_le_net = wait_for_job(response_cw_le_net)\n",
    "\n",
    "response_le_net_infer_le_net_fgm = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"infer\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "         [\n",
    "             f\"-P run_id={response_cw_le_net['mlflowRunId']}\",\n",
    "             f\"-P model_version={model_id_shallow}\",\n",
    "             f\"-P model_name={mnist_shallow}\",\n",
    "        ]\n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    "    depends_on=response_cw_le_net[\"jobId\"],\n",
    ")\n",
    "\n",
    "print(\"Dependent jobs submitted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block does the same as the previous block, but applies the feature squeezing defense between the attack and infer steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_cw_le_net = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"cw_inf\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P model_name={mnist_shallow}\", \n",
    "            f\"-P model_version={model_id_shallow}\", \n",
    "            \"-P model_architecture=shallow_net\",\n",
    "            \"-P targeted=True\", \n",
    "            \"-P max_iter=20\",\n",
    "            \"-P confidence=0.0\", \n",
    "            f\"-P testing_dir={mnist_dataset_testing}\", \n",
    "            \"-P learning_rate=0.01\", \n",
    "            \"-P verbose=True\", \n",
    "            \"-P batch_size=32\"\n",
    "        ]\n",
    "\n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    ")\n",
    "\n",
    "print_response(\"Attack\", \"CW Inf\", response_cw_le_net)\n",
    "response_cw_le_net = wait_for_job(response_cw_le_net)\n",
    "\n",
    "response_feature_squeeze = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"feature_squeeze\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={response_cw_le_net['mlflowRunId']}\",\n",
    "            f\"-P model={mnist_shallow}/{model_id_shallow}\",\n",
    "            \"-P model_architecture=shallow_net\",\n",
    "            \"-P bit_depth=1\",\n",
    "            \"-P batch_size=32\"\n",
    "        ]\n",
    "    ),\n",
    "    depends_on=response_cw_le_net[\"jobId\"],\n",
    "    queue = mlflow_queue,\n",
    ")\n",
    "\n",
    "print_response(\"Defense\", \"Feature Squeezing\", response_feature_squeeze)\n",
    "response_feature_squeeze = wait_for_job(response_feature_squeeze)\n",
    "\n",
    "response_le_net_infer_le_net_cw = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"infer\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={response_feature_squeeze['mlflowRunId']}\",\n",
    "            f\"-P model_name={mnist_shallow}\",\n",
    "            f\"-P model_version={model_id_shallow}\"\n",
    "        ]\n",
    "    ),\n",
    "    depends_on=response_feature_squeeze[\"jobId\"],\n",
    "    queue = mlflow_queue,\n",
    ")\n",
    "\n",
    "print(\"Dependent jobs submitted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block uses the carlini-wagner attack using the L2 distance metric to generate adversarial images and checks the model's accuracy against the attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_cw_shallow_net = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"cw_l2\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P model_name={mnist_shallow}\",\n",
    "            f\"-P model_version={model_id_shallow}\",\n",
    "            \"-P binary_search_steps=50\", \n",
    "            \"-P initial_const=0.01\",\n",
    "            \"-P model_architecture=shallow_net\",\n",
    "            \"-P max_iter=10\",\n",
    "            f\"-P testing_dir={mnist_dataset_testing}\",\n",
    "            \"-P verbose=True\",\n",
    "            \"-P batch_size=1\"]\n",
    "\n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    "\n",
    ")\n",
    "\n",
    "print_response(\"Attack\", \"CW L2\", response_cw_shallow_net)\n",
    "response_cw_shallow_net = wait_for_job(response_cw_shallow_net)\n",
    "\n",
    "response_le_net_infer_shallow_net_cw = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"infer\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={response_cw_shallow_net['mlflowRunId']}\",\n",
    "            f\"-P model_name={mnist_model}\",\n",
    "            f\"-P model_version={model_id}\",\n",
    "        ]\n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    "    depends_on=response_cw_shallow_net[\"jobId\"],\n",
    ")\n",
    "\n",
    "print(\"Dependent jobs submitted\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block does the same as the previous block, but applies the feature squeezing defense between the attack and infer steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependent jobs submitted\n"
     ]
    }
   ],
   "source": [
    "response_cw_shallow_net = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"cw_l2\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P model_name={mnist_shallow}\", \n",
    "            f\"-P model_version={model_id_shallow}\", \n",
    "            \"-P binary_search_steps=50\", \n",
    "            \"-P initial_const=0.01\",\n",
    "            \"-P model_architecture=shallow_net\",\n",
    "            \"-P max_iter=10\",\n",
    "            f\"-P testing_dir={mnist_dataset_testing}\", \n",
    "            \"-P verbose=True\", \n",
    "            \"-P batch_size=32\"\n",
    "        ]\n",
    "\n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    ")\n",
    "\n",
    "print_response(\"Attack\", \"CW L2\", response_cw_shallow_net)\n",
    "response_cw_shallow_net = wait_for_job(response_cw_shallow_net)\n",
    "\n",
    "response_feature_squeeze = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"feature_squeeze\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={response_cw_shallow_net['mlflowRunId']}\",\n",
    "            f\"-P model={mnist_shallow}/{model_id_shallow}\",\n",
    "            \"-P model_architecture=shallow_net\",\n",
    "            \"-P bit_depth=1\",\n",
    "            \"-P batch_size=32\"\n",
    "        ]\n",
    "    ),\n",
    "    depends_on=response_cw_le_net[\"jobId\"],\n",
    "    queue = mlflow_queue,\n",
    ")\n",
    "\n",
    "print_response(\"Defense\", \"Feature Squeezing\", response_feature_squeeze)\n",
    "response_feature_squeeze = wait_for_job(response_feature_squeeze)\n",
    "\n",
    "response_le_net_infer_le_net_cw = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"infer\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={response_feature_squeeze['mlflowRunId']}\",\n",
    "            f\"-P model_name={mnist_shallow}\",\n",
    "            f\"-P model_version={model_id_shallow}\"\n",
    "        ]\n",
    "    ),\n",
    "    depends_on=response_feature_squeeze[\"jobId\"],\n",
    "    queue = mlflow_queue,\n",
    ")\n",
    "\n",
    "print(\"Dependent jobs submitted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block uses the Deepfool attack to generate adversarial MNIST images, applies the feature squeezing defense, and checks the model's accuracy against the defended adversarial dataset.\n",
    "\n",
    "**Unique Deepfool parameters**\n",
    "\n",
    "| parameter | type | description |\n",
    "| --- | --- | --- |\n",
    "| `epsilon` | _float_ | Overshoot parameter. [default: 0.00001] |\n",
    "| `nb_grads` | _int_ | Number of class gradients to compute. [default: 10] |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_deepfool_le_net = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"deepfool\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P model_name={mnist_model}\",\n",
    "            f\"-P training_dir={mnist_dataset_training}\",\n",
    "            \"-P batch_size=1\",\n",
    "            \"-P max_iter=10\",\n",
    "            \"-P nb_grads=10\",\n",
    "            \"-P epsilon=0.001\",\n",
    "            \"-P image_size=[28,28]\"\n",
    "        ],\n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    ")\n",
    "\n",
    "print_response(\"Attack\", \"Deepfool\", response_deepfool_le_net)\n",
    "response_deepfool_le_net = wait_for_job(response_deepfool_le_net)\n",
    "\n",
    "response_le_net_infer_deepfool = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"infer\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={response_deepfool_le_net['mlflowRunId']}\",\n",
    "            f\"-P model_name={mnist_model}\",\n",
    "        ]\n",
    "    ),\n",
    "    depends_on=response_deepfool_le_net[\"jobId\"],\n",
    "    queue = mlflow_queue,\n",
    ")\n",
    "\n",
    "print(\"Dependent jobs submitted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block does the same as the previous block, but applies the feature squeezing defense between the attack and infer steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_deepfool_le_net = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"deepfool\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P model_name={mnist_model}\",\n",
    "            f\"-P training_dir={mnist_dataset_training}\",\n",
    "            \"-P batch_size=1\",\n",
    "            \"-P max_iter=10\",\n",
    "            \"-P nb_grads=10\",\n",
    "            \"-P epsilon=0.01\",\n",
    "        ],\n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    ")\n",
    "\n",
    "print_response(\"Attack\", \"Deepfool\", response_deepfool_le_net)\n",
    "response_deepfool_le_net = wait_for_job(response_deepfool_le_net)\n",
    "\n",
    "response_feature_squeeze = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"feature_squeeze\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={response_deepfool_le_net['mlflowRunId']}\",\n",
    "            f\"-P model={mnist_model}/{model_id}\",\n",
    "            \"-P model_architecture=le_net\",\n",
    "            \"-P bit_depth=1\",\n",
    "            \"-P batch_size=1\",\n",
    "        ],\n",
    "    ),\n",
    "    depends_on=response_deepfool_le_net[\"jobId\"],\n",
    "    queue = mlflow_queue,\n",
    ")\n",
    "print_response(\"Defense\", \"Feature Squeezing\", response_feature_squeeze)\n",
    "response_feature_squeeze = wait_for_job(response_feature_squeeze)\n",
    "\n",
    "response_le_net_infer_le_net_fgm = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"infer\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={response_feature_squeeze['mlflowRunId']}\",\n",
    "            f\"-P model_name={mnist_model}\",\n",
    "        ],\n",
    "    ),\n",
    "    depends_on=response_feature_squeeze[\"jobId\"],\n",
    "    queue = mlflow_queue,\n",
    ")\n",
    "\n",
    "print(\"Dependent jobs submitted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block applies the Jacobian Saliency Map Approach attack to generate adversarial images for the MNIST dataset.\n",
    "\n",
    "**Unique JSMA parameters**\n",
    "\n",
    "| parameter | type | description |\n",
    "| --- | --- | --- |\n",
    "| `theta` | _float_ | Amount of Perturbation introduced to each modified feature per step (can be positive or negative). [default: 0.1] |\n",
    "| `gamma` | _float_ | Maximum fraction of features being perturbed (between 0 and 1). [default: 1.0] |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_jsma = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"jsma\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P model_name={mnist_model}\",\n",
    "            f\"-P model_version={model_id}\", \n",
    "            \"-P theta=4.5\",\n",
    "            \"-P gamma=1.0\", \n",
    "            f\"-P testing_dir={mnist_dataset_testing}\"\n",
    "        ] \n",
    "\n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    "\n",
    ")\n",
    "\n",
    "print_response(\"Attack\", \"JSMA\", response_jsma)\n",
    "response_jsma = wait_for_job(response_jsma)\n",
    "\n",
    "response_le_net_infer_jsma = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"infer\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={response_jsma['mlflowRunId']}\",\n",
    "            f\"-P model_name={mnist_model}\",\n",
    "            f\"-P model_version={model_id}\",\n",
    "        ]\n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    "    depends_on=response_jsma[\"jobId\"],\n",
    ")\n",
    "\n",
    "print(\"Dependent jobs submitted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block does the same as the previous block, but applies the feature squeezing defense between the attack and infer steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_jsma = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"jsma\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P model_name={mnist_model}\",\n",
    "            f\"-P model_version={model_id}\", \n",
    "            \"-P theta=4.5\",\n",
    "            \"-P gamma=1.0\", \n",
    "            f\"-P testing_dir={mnist_dataset_testing}\"\n",
    "        ] \n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    ")\n",
    "\n",
    "print_response(\"Attack\", \"JSMA\", response_jsma)\n",
    "response_jsma = wait_for_job(response_jsma)\n",
    "\n",
    "response_feature_squeeze = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"feature_squeeze\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={response_jsma['mlflowRunId']}\",\n",
    "            f\"-P model={mnist_model}/{model_id}\",\n",
    "            \"-P model_architecture=le_net\",\n",
    "            \"-P bit_depth=1\",\n",
    "            \"-P batch_size=32\"\n",
    "        ]\n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    "    depends_on=response_jsma[\"jobId\"],\n",
    ")\n",
    "\n",
    "print_response(\"Defense\", \"Feature Squeezing\", response_feature_squeeze)\n",
    "response_feature_squeeze = wait_for_job(response_feature_squeeze)\n",
    "\n",
    "response_le_net_infer_le_net_jsma = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"infer\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={response_feature_squeeze['mlflowRunId']}\",\n",
    "            f\"-P model_name={mnist_model}\",\n",
    "            f\"-P model_version={model_id}\",\n",
    "        ]\n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    "    depends_on=response_feature_squeeze[\"jobId\"],\n",
    ")\n",
    "\n",
    "print(\"Dependent jobs submitted\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "edee40310913f16e2ca02c1d37887bcb7f07f00399ca119bb7e27de7d632ea99"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
