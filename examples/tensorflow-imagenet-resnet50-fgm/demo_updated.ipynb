{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow ImageNet Resnet50 FGM demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">⚠️ **Warning:** This demo assumes that you have access to an on-prem deployment of Dioptra that provides a copy of the ImageNet dataset and a CUDA-compatible GPU.\n",
    "> This demo cannot be run on a typical personal computer.\n",
    "\n",
    "The notebook contains an example of the FGM attack on the ResNet50 architecture with optional defense entry points.\n",
    "Users can also explore the following preprocessing defenses from their associated defense entry points:\n",
    "\n",
    "-   **Spatial Smoothing:** Smooths out an image by passing a median filter through neighboring pixel values in images.\n",
    "-   **Gaussian Augmentation:** Adds gaussian noise to an image.\n",
    "-   **JPEG Compression:** Applies an image compression algorithm over the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** This demo is specifically for the NCCoE DGX Workstation with hostname `dgx-station-2`.\n",
    "\n",
    "Port forwarding is required in order to run this demo.\n",
    "The recommended port mapping is as follows:\n",
    "\n",
    "- Map `*:20080` on laptop to `localhost:30080` on `dgx-station-2`\n",
    "- Map `*:25000` on laptop to `localhost:35000` on `dgx-station-2`\n",
    "\n",
    "A sample SSH config file that enables the above port forwarding is provided below,\n",
    "\n",
    "> ⚠️ **Edits required**: replace `username` with your assigned username _on the NCCoE virtual machines_!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```conf\n",
    "# vm hostname: jumphost001\n",
    "Host nccoe-jumphost001\n",
    "    Hostname 10.33.53.98\n",
    "    User username  # Change to your assigned username on the NCCoE virtual machines!\n",
    "    Port 54131\n",
    "    IdentityFile %d/.ssh/nccoe-vm\n",
    "\n",
    "# vm hostname: dgx-station-2\n",
    "Host nccoe-k8s-gpu002\n",
    "    Hostname 192.168.1.28\n",
    "    User username  # Change to your assigned username on the NCCoE virtual machines!\n",
    "    Port 22\n",
    "    IdentityFile %d/.ssh/nccoe-vm\n",
    "    ProxyJump nccoe-jumphost001\n",
    "    LocalForward *:20080 localhost:30080\n",
    "    LocalForward *:25000 localhost:35000\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, connect to the NCCoE VPN and SSH into the DGX Workstation,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "ssh nccoe-k8s-gpu002\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we import the necessary Python modules and ensure the proper environment variables are set so that all the code blocks will work as expected.\n",
    "\n",
    "> ⚠️ **Edits possibly required**: update the value of the `HOST_DOCKER_INTERNAL` variable\n",
    "\n",
    "If this notebook is being served to you via Docker (i.e. you ran `make jupyter` to launch this notebook), **then you may need to change the value assigned to the variable `HOST_DOCKER_INTERNAL`** to make the port forwarding you configured in the previous step accessible within the container.\n",
    "The value you need to assign to the variable to depends on your host device's operating system:\n",
    "\n",
    "- **Case 1: Host operating system is Windows 10 or MacOS**\n",
    "  - Set `HOST_DOCKER_INTERNAL = \"host.docker.internal\"`. This is the default setting.\n",
    "- **Case 2: Host operating system is Linux**\n",
    "  - Run either `ip address` or `ifconfig` to print a list of the available network interfaces on your host device\n",
    "  - Locate the `docker0` interface and take note of the associated IP address (this is commonly set to `172.17.0.1`)\n",
    "  - Set `HOST_DOCKER_INTERNAL` equal to the IP address for the `docker0` interface. So, if the IP address was `172.17.0.1`, then you would set `HOST_DOCKER_INTERNAL = \"172.17.0.1\"`\n",
    "  \n",
    "If you started your Jupyter Lab instance from a conda environment, then you do not need to change anything.\n",
    "The code below uses an environment variable to check whether this notebook is being served via the `jupyter` service, and if that variable isn't found, then the connection address reverts to `localhost` and ignores the `HOST_DOCKER_INTERNAL` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages from the Python standard library\n",
    "import os\n",
    "import pprint\n",
    "import time\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "\n",
    "# Please enter custom username here.\n",
    "USERNAME = \"howard\"\n",
    "\n",
    "# Filter out warning messages\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Address for connecting the docker container to exposed ports on the host device\n",
    "HOST_DOCKER_INTERNAL = \"host.docker.internal\"\n",
    "# HOST_DOCKER_INTERNAL = \"172.17.0.1\"\n",
    "\n",
    "# Testbed API ports\n",
    "RESTAPI_PORT = \"30080\"\n",
    "MLFLOW_TRACKING_PORT = \"35000\"\n",
    "\n",
    "# Default address for accessing the RESTful API service\n",
    "RESTAPI_ADDRESS = (\n",
    "    f\"http://{HOST_DOCKER_INTERNAL}:{RESTAPI_PORT}\"\n",
    "    if os.getenv(\"IS_JUPYTER_SERVICE\")\n",
    "    else f\"http://localhost:{RESTAPI_PORT}\"\n",
    ")\n",
    "\n",
    "# Override the AI_RESTAPI_URI variable, used to connect to RESTful API service\n",
    "os.environ[\"AI_RESTAPI_URI\"] = RESTAPI_ADDRESS\n",
    "\n",
    "# Default address for accessing the MLFlow Tracking server\n",
    "MLFLOW_TRACKING_URI = (\n",
    "    f\"http://{HOST_DOCKER_INTERNAL}:{MLFLOW_TRACKING_PORT}\"\n",
    "    if os.getenv(\"IS_JUPYTER_SERVICE\")\n",
    "    else f\"http://localhost:{MLFLOW_TRACKING_PORT}\"\n",
    ")\n",
    "\n",
    "# Override the MLFLOW_TRACKING_URI variable, used to connect to MLFlow Tracking service\n",
    "os.environ[\"MLFLOW_TRACKING_URI\"] = MLFLOW_TRACKING_URI\n",
    "\n",
    "# Path to custom task plugins archives\n",
    "CUSTOM_PLUGINS_EVALUATION_TAR_GZ = Path(\"custom-plugins-evaluation.tar.gz\")\n",
    "\n",
    "# Base API address\n",
    "RESTAPI_API_BASE = f\"{RESTAPI_ADDRESS}/api\"\n",
    "\n",
    "# Path to workflows archive\n",
    "WORKFLOWS_TAR_GZ = Path(\"workflows.tar.gz\")\n",
    "\n",
    "# Experiment name (note the username_ prefix convention)\n",
    "EXPERIMENT_NAME = f\"{USERNAME}_imagenet_fgm_defense\"\n",
    "\n",
    "# Path to dataset\n",
    "data_path_imagenet = \"/nfs/data/ImageNet-Kaggle-2017/images/ILSVRC/Data/CLS-LOC\"\n",
    "\n",
    "# Import third-party Python packages\n",
    "import numpy as np\n",
    "import requests\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# Import utils.py file\n",
    "import utils\n",
    "\n",
    "# Create random number generator\n",
    "rng = np.random.default_rng(54399264723942495723666216079516778448)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ImageNet dataset needed for the demo is available in all worker containers at the path `/nfs/data/ImageNet-Kaggle-2017/images/ILSVRC/Data/CLS-LOC/`.\n",
    "The following directores contain labeled JPEG images:\n",
    "\n",
    "    train  \n",
    "    val-sorted  \n",
    "    val-sorted-1000\n",
    "    val-sorted-5000\n",
    "    val-sorted-10000  \n",
    "    \n",
    "Both `train` and `val-sorted` contain a full set of labeled training and test images.\n",
    "The `val-sorted-#` directories hold a random partion of labeled images, with 1000, 5000, or 10000 images in total. \n",
    "\n",
    "Each of the directories listed follows the general subfolder structure below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ImageNet\n",
    "    ├── train\n",
    "    │   ├── {class 0 directory}\n",
    "    │   ├── {class 1 directory}\n",
    "    │   ├── ...\n",
    "    │   ├── ...\n",
    "    │   ├── ...\n",
    "    │   └── {class 999 directory}\n",
    "    ├── val-sorted\n",
    "    │   ├── {class 0 directory}\n",
    "    │   ├── {class 1 directory}\n",
    "    │   ├── ...\n",
    "    │   ├── ...\n",
    "    │   ├── ...\n",
    "    │   └── {class 999 directory}\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The subfolders under each directory are the classification labels for the images in the dataset.\n",
    "This folder structure is a standardized way to encode the label information and many libraries can make use of it, including the Tensorflow library that we are using for this particular demo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit and run jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entrypoints that we will be running in this example are implemented in the Python source files under `src/` and the `MLproject` file.\n",
    "To run these entrypoints within the testbed architecture, we need to package those files up into an archive and submit it to the Testbed RESTful API to create a new job.\n",
    "For convenience, the `Makefile` provides a rule for creating the archive file for this example, just run `make workflows`,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Create the workflows.tar.gz file\n",
    "make workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To connect with the endpoint, we will use a client class defined in the `utils.py` file that is able to connect with the Testbed RESTful API using the HTTP protocol.\n",
    "We connect using the client below, which uses the environment variable `AI_RESTAPI_URI` to figure out how to connect to the Testbed RESTful API,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restapi_client = utils.SecuringAIClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to register an experiment under which to collect our job runs.\n",
    "The code below checks if the relevant experiment exists.\n",
    "If it does, then it just returns info about the experiment, if it doesn't, it then registers the new experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_experiment = restapi_client.get_experiment_by_name(name=EXPERIMENT_NAME)\n",
    "\n",
    "if response_experiment is None or \"Not Found\" in response_experiment.get(\"message\", []):\n",
    "    response_experiment = restapi_client.register_experiment(name=EXPERIMENT_NAME)\n",
    "\n",
    "response_experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should also check which queues are available for running our jobs to make sure that the resources that we need are available.\n",
    "The code below queries the Testbed API and returns a list of active queues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restapi_client.list_queues()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_queue = restapi_client.get_queue_by_name(name=\"tensorflow_cpu\")\n",
    "\n",
    "if response_queue is None or \"Not Found\" in response_queue.get(\"message\", []):\n",
    "    response_queue = restapi_client.register_queue(name=\"tensorflow_cpu\")\n",
    "\n",
    "response_queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example also makes use of the `custom_fgm_patch_poisoning_plugins` custom task plugin package stored locally under the `task-plugins/securingai_custom/custom_fgm_patch_poisoning_plugins` directory.\n",
    "To register these custom task plugins, we first need to package them up into an archive.\n",
    "For convenience, the `Makefile` provides a rule for creating the custom task plugins archive file, just run `make custom-plugins`,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Create the workflows.tar.gz file\n",
    "make custom-plugins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the custom task plugin package is packaged into an archive file, next we register it by uploading the file to the REST API.\n",
    "Note that we need to provide the name to use for custom task plugin package, this name must be unique under the custom task plugins namespace.\n",
    "For a full list of the custom task plugins, use `restapi_client.restapi_client.list_custom_task_plugins()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restapi_client.delete_custom_task_plugin(name=\"custom_fgm_patch_poisoning_plugins\")\n",
    "response_custom_plugins = restapi_client.get_custom_task_plugin(name=\"custom_fgm_patch_poisoning_plugins\")\n",
    "\n",
    "if response_custom_plugins is None or \"Not Found\" in response_custom_plugins.get(\"message\", []):\n",
    "    response_custom_plugins = restapi_client.upload_custom_plugin_package(\n",
    "        custom_plugin_name=\"custom_fgm_patch_poisoning_plugins\",\n",
    "        custom_plugin_file=CUSTOM_PLUGINS_EVALUATION_TAR_GZ,\n",
    "    )\n",
    "\n",
    "response_custom_plugins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If at any point you need to update one or more files within the `evaluation` plugin package, you will need to unregister/delete the custom task plugin first using the REST API.\n",
    "This can be done as follows,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Delete the 'evaluation' custom task plugin package\n",
    "restapi_client.delete_custom_task_plugin(name=\"custom_fgm_patch_poisoning_plugins\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FGM Model Setup and Attack\n",
    "\n",
    "For this section of the demo we will first start by loading in the respective baseline ResNet50 model and evaluating its performance on a subset of the ImageNet validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_init_model = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"init_model\",\n",
    "    entry_point_kwargs=\" \".join([\n",
    "        \"-P batch_size=20\",\n",
    "        \"-P model_architecture=resnet50\",\n",
    "        f\"-P register_model_name={EXPERIMENT_NAME}_pretrained_resnet50\",\n",
    "        \"-P imagenet_preprocessing=true\",\n",
    "        \"-P image_size=224,224,3\",\n",
    "        f\"-P data_dir={data_path_imagenet}/val-sorted-1000\",\n",
    "    ]),\n",
    "    queue=\"tensorflow_gpu\",\n",
    "    timeout=\"1h\",\n",
    ")\n",
    "\n",
    "print(\"Model initialization and ImageNet evaluation job submitted.\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_init_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our baseline model loaded and stored, next we will apply the fast-gradient method (FGM) evasion attack on the model to generate adversarial images.\n",
    "Then, after we have the adversarial images, we will reapply the attack with spatial smoothing defense enabled.\n",
    "We will then test the model under both sets of images (FGM attack, FGM attack + preprocessing defense) and apply standard machine learning accuracy metrics on the inference results. \n",
    "This will give us a general sense of the effectivness and robustness of the FGM evasion attack with regards to a particular preprocessing defense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlflow_run_id_is_not_known(response):\n",
    "    return response[\"mlflowRunId\"] is None and response[\"status\"] not in [\n",
    "        \"failed\",\n",
    "        \"finished\",\n",
    "    ]\n",
    "\n",
    "response_fgm_resnet50_attack = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"fgm\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P model_name={EXPERIMENT_NAME}_pretrained_resnet50\",\n",
    "            \"-P model_version=None\",\n",
    "            f\"-P data_dir={data_path_imagenet}/val-sorted-1000\",\n",
    "            \"-P batch_size=20\",\n",
    "            \"-P eps_step=0.1\",\n",
    "            \"-P imagenet_preprocessing=true\",\n",
    "            \"-P image_size=224,224,3\",\n",
    "            \"-P eps=10\"\n",
    "        ]\n",
    "    ),\n",
    "    queue=\"tensorflow_gpu\",\n",
    "    depends_on=response_init_model['jobId']\n",
    ")\n",
    "\n",
    "print(\"FGM attack (ResNet50 architecture) job submitted\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_fgm_resnet50_attack)\n",
    "print(\"\")\n",
    "\n",
    "# Wait for FGM attack to complete.Then evaluate results.\n",
    "while mlflow_run_id_is_not_known(response_fgm_resnet50_attack):\n",
    "    time.sleep(1)\n",
    "    response_fgm_resnet50_attack = restapi_client.get_job_by_id(response_fgm_resnet50_attack[\"jobId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_evaluate_fgm_resnet50_attack = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"infer\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={response_fgm_resnet50_attack['mlflowRunId']}\",\n",
    "            f\"-P model_name={EXPERIMENT_NAME}_pretrained_resnet50\",\n",
    "            \"-P model_version=None\",\n",
    "            \"-P batch_size=20\",\n",
    "            \"-P adv_tar_name=testing_adversarial_fgm.tar.gz\",\n",
    "            \"-P adv_data_dir=adv_testing\",\n",
    "            \"-P imagenet_preprocessing=true\",\n",
    "            \"-P image_size=224,224,3\",\n",
    "        ]\n",
    "    ),\n",
    "    queue=\"tensorflow_gpu\",\n",
    "    depends_on=response_fgm_resnet50_attack[\"jobId\"],\n",
    ")\n",
    "\n",
    "print(\"FGM evaluation (ResNet50 architecture) job submitted\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_evaluate_fgm_resnet50_attack)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Preprocessing Defenses\n",
    "Now we will apply our defenses over the fgm-attacked images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_fgm_resnet50_attack_def = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"spatial_smoothing\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P data_dir={data_path_imagenet}/val-sorted-1000\",\n",
    "            \"-P batch_size=20\",\n",
    "            \"-P load_dataset_from_mlruns=true\",\n",
    "            f\"-P dataset_run_id={response_fgm_resnet50_attack['mlflowRunId']}\",\n",
    "            \"-P dataset_tar_name=testing_adversarial_fgm.tar.gz\",\n",
    "            \"-P dataset_name=adv_testing\",\n",
    "            \"-P image_size=224,224,3\",\n",
    "            \n",
    "        ]\n",
    "    ),\n",
    "    queue=\"tensorflow_gpu\",\n",
    "    depends_on=response_fgm_resnet50_attack[\"jobId\"],\n",
    ")\n",
    "\n",
    "print(\"FGM spatial smoothing defense (ResNet50 architecture) job submitted\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_fgm_resnet50_attack_def)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while mlflow_run_id_is_not_known(response_fgm_resnet50_attack_def):\n",
    "    time.sleep(1)\n",
    "    response_fgm_resnet50_attack_def = restapi_client.get_job_by_id(response_fgm_resnet50_attack_def[\"jobId\"])\n",
    "    \n",
    "    \n",
    "response_evaluate_fgm_resnet50_attack_def = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"infer\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={response_fgm_resnet50_attack_def['mlflowRunId']}\",\n",
    "            f\"-P model_name={EXPERIMENT_NAME}_pretrained_resnet50\",\n",
    "            \"-P model_version=None\",\n",
    "            \"-P batch_size=20\",\n",
    "            \"-P adv_tar_name=spatial_smoothing_dataset.tar.gz\",\n",
    "            \"-P adv_data_dir=adv_testing\",\n",
    "            \"-P imagenet_preprocessing=true\",\n",
    "            \"-P image_size=224,224,3\",\n",
    "        ]\n",
    "    ),\n",
    "    queue=\"tensorflow_gpu\",\n",
    "    depends_on=response_fgm_resnet50_attack_def[\"jobId\"],\n",
    ")\n",
    "\n",
    "print(\"FGM evaluation (ResNet50 architecture) job submitted\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_evaluate_fgm_resnet50_attack_def)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_fgm_resnet50_attack_def = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"gaussian_augmentation\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P data_dir={data_path_imagenet}/val-sorted-1000\",\n",
    "            \"-P batch_size=20\",\n",
    "            \"-P load_dataset_from_mlruns=true\",\n",
    "            f\"-P dataset_run_id={response_fgm_resnet50_attack['mlflowRunId']}\",\n",
    "            \"-P dataset_tar_name=testing_adversarial_fgm.tar.gz\",\n",
    "            \"-P dataset_name=adv_testing\",\n",
    "            \"-P image_size=224,224,3\",\n",
    "            \n",
    "        ]\n",
    "    ),\n",
    "    queue=\"tensorflow_gpu\",\n",
    "    depends_on=response_fgm_resnet50_attack[\"jobId\"],\n",
    ")\n",
    "\n",
    "print(\"FGM gaussian augmentation defense (ResNet50 architecture) job submitted\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_fgm_resnet50_attack_def)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while mlflow_run_id_is_not_known(response_fgm_resnet50_attack_def):\n",
    "    time.sleep(1)\n",
    "    response_fgm_resnet50_attack_def = restapi_client.get_job_by_id(response_fgm_resnet50_attack_def[\"jobId\"])\n",
    "    \n",
    "    \n",
    "response_evaluate_fgm_resnet50_attack_def = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"infer\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={response_fgm_resnet50_attack_def['mlflowRunId']}\",\n",
    "            f\"-P model_name={EXPERIMENT_NAME}_pretrained_resnet50\",\n",
    "            \"-P model_version=None\",\n",
    "            \"-P batch_size=20\",\n",
    "            \"-P adv_tar_name=gaussian_augmentation_dataset.tar.gz\",\n",
    "            \"-P adv_data_dir=adv_testing\",\n",
    "            \"-P imagenet_preprocessing=true\",\n",
    "            \"-P image_size=224,224,3\",\n",
    "        ]\n",
    "    ),\n",
    "    queue=\"tensorflow_gpu\",\n",
    "    depends_on=response_fgm_resnet50_attack_def[\"jobId\"],\n",
    ")\n",
    "\n",
    "print(\"FGM evaluation (ResNet50 architecture) job submitted\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_evaluate_fgm_resnet50_attack_def)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_fgm_resnet50_attack_def = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"jpeg_compression\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P data_dir={data_path_imagenet}/val-sorted-1000\",\n",
    "            \"-P batch_size=20\",\n",
    "            \"-P load_dataset_from_mlruns=true\",\n",
    "            f\"-P dataset_run_id={response_fgm_resnet50_attack['mlflowRunId']}\",\n",
    "            \"-P dataset_tar_name=testing_adversarial_fgm.tar.gz\",\n",
    "            \"-P dataset_name=adv_testing\",\n",
    "            \"-P image_size=224,224,3\",\n",
    "            \n",
    "        ]\n",
    "    ),\n",
    "    queue=\"tensorflow_gpu\",\n",
    "    depends_on=response_fgm_resnet50_attack[\"jobId\"],\n",
    ")\n",
    "\n",
    "print(\"FGM JPEG compression defense (ResNet50 architecture) job submitted\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_fgm_resnet50_attack_def)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while mlflow_run_id_is_not_known(response_fgm_resnet50_attack_def):\n",
    "    time.sleep(1)\n",
    "    response_fgm_resnet50_attack_def = restapi_client.get_job_by_id(response_fgm_resnet50_attack_def[\"jobId\"])\n",
    "    \n",
    "    \n",
    "response_evaluate_fgm_resnet50_attack_def = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"infer\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={response_fgm_resnet50_attack_def['mlflowRunId']}\",\n",
    "            f\"-P model_name={EXPERIMENT_NAME}_pretrained_resnet50\",\n",
    "            \"-P model_version=None\",\n",
    "            \"-P batch_size=20\",\n",
    "            \"-P adv_tar_name=jpeg_compression_dataset.tar.gz\",\n",
    "            \"-P adv_data_dir=adv_testing\",\n",
    "            \"-P imagenet_preprocessing=true\",\n",
    "            \"-P image_size=224,224,3\",\n",
    "        ]\n",
    "    ),\n",
    "    queue=\"tensorflow_gpu\",\n",
    "    depends_on=response_fgm_resnet50_attack_def[\"jobId\"],\n",
    ")\n",
    "\n",
    "print(\"FGM evaluation (ResNet50 architecture) job submitted\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_evaluate_fgm_resnet50_attack_def)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "edee40310913f16e2ca02c1d37887bcb7f07f00399ca119bb7e27de7d632ea99"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
