# This Software (Dioptra) is being made available as a public service by the
# National Institute of Standards and Technology (NIST), an Agency of the United
# States Department of Commerce. This software was developed in part by employees of
# NIST and in part by NIST contractors. Copyright in portions of this software that
# were developed by NIST contractors has been licensed or assigned to NIST. Pursuant
# to Title 17 United States Code Section 105, works of NIST employees are not
# subject to copyright protection in the United States. However, NIST may hold
# international copyright in software created by its employees and domestic
# copyright (or licensing rights) in portions of software that were assigned or
# licensed to NIST. To the extent that NIST holds copyright in this software, it is
# being made available under the Creative Commons Attribution 4.0 International
# license (CC BY 4.0). The disclaimers of the CC BY 4.0 license apply to all parts
# of the software developed or licensed by NIST.
#
# ACCESS THE FULL CC BY 4.0 LICENSE HERE:
# https://creativecommons.org/licenses/by/4.0/legalcode
name: imagenet-resnet50-fgm

entry_points:
  gen_patch:
    parameters:
      data_dir: {type: path, default: "/dioptra/data/Mnist/training" }
      model_name: { type: string, default: "mnist_adversarial_patch_le_net" }
      model_version: { type: string, default: "1" }
      image_size: { type: string, default: "[28,28,1]" }
      adv_tar_name: { type: string, default: "adversarial_patch.tar.gz" }
      adv_data_dir: { type: string, default: "adv_patches" }
      rotation_max: {type: float, default: 22.5}
      scale_min: {type: float, default: 0.1}
      scale_max: {type: float, default: 1.0}
      learning_rate: {type: float, default: 5.0}
      max_iter: {type: int, default: 500}
      patch_target: {type: int, default: -1}
      num_patch: {type: int, default: 1}
      num_patch_gen_samples: {type: int, default: 10}
      imagenet_preprocessing: { type: string, default: "false"}
      seed: {type: float, default: -1}
    command: >
      PYTHONPATH=$DIOPTRA_PLUGIN_DIR validate-experiment generate_patch.yml && PYTHONPATH=$DIOPTRA_PLUGIN_DIR run-experiment generate_patch.yml
      -P data_dir={data_dir}
      -P rotation_max={rotation_max}
      -P scale_max={scale_max}
      -P scale_min={scale_min}
      -P learning_rate={learning_rate}
      -P max_iter={max_iter}
      -P patch_target={patch_target}
      -P num_patch={num_patch}
      -P num_patch_gen_samples={num_patch_gen_samples}
      -P image_size={image_size}
      -P adv_tar_name={adv_tar_name}
      -P adv_data_dir={adv_data_dir}
      -P model_name={model_name}
      -P model_version={model_version}
      -P imagenet_preprocessing={imagenet_preprocessing}
      -P seed={seed}

  deploy_patch:
    parameters:
      data_dir: {type: path, default: "/dioptra/data/Mnist/testing" }
      run_id: {type: string}
      model_name: { type: string, default: "mnist_adversarial_patch_le_net" }
      model_version: { type: string, default: "1" }
      image_size: { type: string, default: "[28,28,1]" }
      adv_tar_name: { type: string, default: "adversarial_patch_dataset.tar.gz" }
      adv_data_dir: { type: string, default: "adv_patch_dataset" }
      adv_patch_tar_name: { type: string, default: "adversarial_patch.tar.gz" }
      adv_patch_dir: { type: string, default: "adv_patches" }
      imagenet_preprocessing: { type: string, default: "false"}
      patch_deployment_method: {type: string, default: "augment"}
      patch_application_rate: {type: string, default: 1.0}
      patch_scale: {type: float, default: 0.4}
      batch_size: {type: float, default: 32}
      rotation_max: {type: float, default: 22.5}
      scale_min: {type: float, default: 0.1}
      scale_max: {type: float, default: 1.0}
      seed: {type: float, default: -1}
    command: >
      PYTHONPATH=$DIOPTRA_PLUGIN_DIR validate-experiment deploy_patch.yml && PYTHONPATH=$DIOPTRA_PLUGIN_DIR run-experiment deploy_patch.yml
      -P run_id={run_id}
      -P data_dir={data_dir}
      -P patch_deployment_method={patch_deployment_method}
      -P patch_application_rate={patch_application_rate}
      -P patch_scale={patch_scale}
      -P batch_size={batch_size}
      -P rotation_max={rotation_max}
      -P scale_max={scale_max}
      -P scale_min={scale_min}
      -P model_name={model_name}
      -P model_version={model_version}
      -P image_size={image_size}
      -P adv_tar_name={adv_tar_name}
      -P adv_data_dir={adv_data_dir}
      -P adv_patch_tar-name={adv_patch_tar_name}
      -P adv_patch_dir={adv_patch_dir}
      -P imagenet_preprocessing={imagenet_preprocessing}
      -P seed={seed}

  spatial_smoothing:
    parameters:
      image_size: { type: string, default: "[28,28,1]" }
      def_tar_name: { type: string, default: "spatial_smoothing_dataset.tar.gz" }
      def_data_dir: { type: string, default: "adv_testing" }
      batch_size: { type: float, default: 32 }
      spatial_smoothing_window_size: {type: int, default: 3}
      spatial_smoothing_apply_fit: {type: string, default: "false"}
      spatial_smoothing_apply_predict: {type: string, default: "true"}
      dataset_run_id: {type: string, default: "none"}
      dataset_tar_name: {type: string, default: "adversarial_patch_dataset.tar.gz"}
      dataset_name: {type: string, default: "adv_patch_dataset"}
      seed: { type: float, default: -1 }
    command: >
      PYTHONPATH=$DIOPTRA_PLUGIN_DIR validate-experiment spatial_smoothing.yml && PYTHONPATH=$DIOPTRA_PLUGIN_DIR run-experiment spatial_smoothing.yml
      -P image_size={image_size}
      -P def_tar_name={def_tar_name}
      -P def_data_dir={def_data_dir}
      -P batch_size={batch_size}
      -P spatial_smoothing_window_size={spatial_smoothing_window_size}
      -P spatial_smoothing_apply_fit={spatial_smoothing_apply_fit}
      -P spatial_smoothing_apply_predict={spatial_smoothing_apply_predict}
      -P dataset_run_id={dataset_run_id}
      -P dataset_tar_name={dataset_tar_name}
      -P dataset_name={dataset_name}
      -P seed={seed}

  jpeg_compression:
    parameters:
      image_size: { type: string, default: "[28,28,1]" }
      def_tar_name: { type: string, default: "jpeg_compression_dataset.tar.gz" }
      def_data_dir: { type: string, default: "adv_testing" }
      batch_size: { type: float, default: 32 }
      jpeg_compression_channels_first: {type: string, default: "false"}
      jpeg_compression_quality: {type: int, default: 50}
      jpeg_compression_apply_fit: {type: string, default: "false"}
      jpeg_compression_apply_predict: {type: string, default: "true"}
      dataset_run_id: {type: string, default: "none"}
      dataset_tar_name: {type: string, default: "adversarial_patch_dataset.tar.gz"}
      dataset_name: {type: string, default: "adv_patch_dataset"}
      seed: { type: float, default: -1 }
    command: >
      PYTHONPATH=$DIOPTRA_PLUGIN_DIR validate-experiment jpeg_compression.yml && PYTHONPATH=$DIOPTRA_PLUGIN_DIR run-experiment jpeg_compression.yml
      -P image_size={image_size}
      -P def_tar_name={def_tar_name}
      -P def_data_dir={def_data_dir}
      -P batch_size={batch_size}
      -P jpeg_compression_channels_first={jpeg_compression_channels_first}
      -P jpeg_compression_quality={jpeg_compression_quality}
      -P jpeg_compression_apply_fit={jpeg_compression_apply_fit}
      -P jpeg_compression_apply_predict={jpeg_compression_apply_predict}
      -P dataset_run_id={dataset_run_id}
      -P dataset_tar_name={dataset_tar_name}
      -P dataset_name={dataset_name}
      -P seed={seed}

  gaussian_augmentation:
    parameters:
      image_size: { type: string, default: "[28,28,1]" }
      def_tar_name: { type: string, default: "gaussian_augmentation_dataset.tar.gz" }
      def_data_dir: { type: string, default: "adv_testing" }
      batch_size: { type: float, default: 32 }
      gaussian_augmentation_perform_data_augmentation: {type: string, default: "false"}
      gaussian_augmentation_ratio: {type: float, default: 1}
      gaussian_augmentation_sigma: {type: float, default: 1}
      gaussian_augmentation_apply_fit: {type: string, default: "false"}
      gaussian_augmentation_apply_predict: {type: string, default: "true"}
      dataset_run_id: {type: string, default: "none"}
      dataset_tar_name: {type: string, default: "adversarial_patch_dataset.tar.gz"}
      dataset_name: {type: string, default: "adv_patch_dataset"}
      seed: { type: float, default: -1 }
    command: >
      PYTHONPATH=$DIOPTRA_PLUGIN_DIR validate-experiment gaussian_augmentation.yml && PYTHONPATH=$DIOPTRA_PLUGIN_DIR run-experiment gaussian_augmentation.yml
      -P image_size={image_size}
      -P def_tar_name={def_tar_name}
      -P def_data_dir={def_data_dir}
      -P batch_size={batch_size}
      -P gaussian_augmentation_perform_data_augmentation={gaussian_augmentation_perform_data_augmentation}
      -P gaussian_augmentation_ratio={gaussian_augmentation_ratio}
      -P gaussian_augmentation_sigma={gaussian_augmentation_sigma}
      -P gaussian_augmentation_apply_fit={gaussian_augmentation_apply_fit}
      -P gaussian_augmentation_apply_predict={gaussian_augmentation_apply_predict}
      -P dataset_run_id={dataset_run_id}
      -P dataset_tar_name={dataset_tar_name}
      -P dataset_name={dataset_name}
      -P seed={seed}

  infer:
    parameters:
      run_id: { type: string }
      image_size: { type: string, default: "[28,28,1]" }
      model_name: { type: string, default: "mnist_adversarial_patch_le_net" }
      model_version: { type: string, default: "1" }
      batch_size: { type: float, default: 32 }
      adv_tar_name: { type: string, default: "adversarial_patch_dataset.tar.gz" }
      adv_data_dir: { type: string, default: "adv_patch_dataset" }
      imagenet_preprocessing: { type: string, default: "false"}
      seed: { type: float, default: -1 }
    command: >
      PYTHONPATH=$DIOPTRA_PLUGIN_DIR validate-experiment infer.yml && PYTHONPATH=$DIOPTRA_PLUGIN_DIR run-experiment infer.yml
      -P run_id={run_id}
      -P image_size={image_size}
      -P model_name={model_name}
      -P model_version={model_version}
      -P batch_size={batch_size}
      -P adv_tar_name={adv_tar_name}
      -P adv_data_dir={adv_data_dir}
      -P imagenet_preprocessing={imagenet_preprocessing}
      -P seed={seed}

  train:
    parameters:
      data_dir_testing: { type: path, default: "/dioptra/data/Mnist/testing" }
      data_dir_training: { type: path, default: "/dioptra/data/Mnist/training" }
      image_size: { type: string, default: "[28,28,1]" }
      model_architecture: { type: string, default: "le_net" }
      epochs: { type: float, default: 30 }
      batch_size: { type: float, default: 32 }
      register_model_name: { type: string, default: "mnist_adversarial_patch_le_net" }
      learning_rate: { type: float, default: 0.001 }
      optimizer: { type: string, default: "Adam" }
      validation_split: { type: float, default: 0.2 }
      seed: { type: float, default: -1 }
    command: >
      PYTHONPATH=$DIOPTRA_PLUGIN_DIR validate-experiment train.yml && PYTHONPATH=$DIOPTRA_PLUGIN_DIR run-experiment train.yml
      -P data_dir_testing={data_dir_testing}
      -P data_dir_training={data_dir_training}
      -P image_size={image_size}
      -P model_architecture={model_architecture}
      -P epochs={epochs}
      -P batch_size={batch_size}
      -P register_model_name={register_model_name}
      -P learning_rate={learning_rate}
      -P optimizer={optimizer}
      -P validation_split={validation_split}
      -P seed={seed}

  train_on_Mnist_patched:
    parameters:
      data_dir_testing: { type: path, default: "/dioptra/data/Mnist/testing" }
      image_size: { type: string, default: "[28,28,1]" }
      model_architecture: { type: string, default: "le_net" }
      epochs: { type: float, default: 30 }
      batch_size: { type: float, default: 32 }
      register_model_name: { type: string, default: "mnist_adversarial_patch_le_net" }
      learning_rate: { type: float, default: 0.001 }
      optimizer: { type: string, default: "Adam" }
      validation_split: { type: float, default: 0.2 }
      dataset_run_id_testing: {type: string, default: ""}
      dataset_run_id_training: {type: string, default: ""}
      adv_tar_name: { type: string, default: "adversarial_patch_dataset.tar.gz" }
      adv_data_dir: { type: string, default: "adv_patch_dataset" }
      seed: { type: float, default: -1 }
    command: >
      PYTHONPATH=$DIOPTRA_PLUGIN_DIR validate-experiment train_on_Mnist_patched.yml && PYTHONPATH=$DIOPTRA_PLUGIN_DIR run-experiment train_on_Mnist_patched.yml
      -P data_dir_testing={data_dir_testing}
      -P image_size={image_size}
      -P model_architecture={model_architecture}
      -P epochs={epochs}
      -P batch_size={batch_size}
      -P register_model_name={register_model_name}
      -P learning_rate={learning_rate}
      -P optimizer={optimizer}
      -P validation_split={validation_split}
      -P dataset_run_id_testing={dataset_run_id_testing}
      -P dataset_run_id_training={dataset_run_id_training}
      -P adv_tar_name={adv_tar_name}
      -P adv_data_dir={adv_data_dir}
      -P seed={seed}

  train_on_Fruits360_patched:
    parameters:
      data_dir_testing: { type: path, default: "/dioptra/data/Mnist/testing" }
      image_size: { type: string, default: "[28,28,1]" }
      model_architecture: { type: string, default: "le_net" }
      epochs: { type: float, default: 30 }
      batch_size: { type: float, default: 32 }
      register_model_name: { type: string, default: "mnist_adversarial_patch_le_net" }
      learning_rate: { type: float, default: 0.001 }
      optimizer: { type: string, default: "Adam" }
      validation_split: { type: float, default: 0.2 }
      dataset_run_id_testing: {type: string, default: ""}
      dataset_run_id_training: {type: string, default: ""}
      adv_tar_name: { type: string, default: "adversarial_patch_dataset.tar.gz" }
      adv_data_dir: { type: string, default: "adv_patch_dataset" }
      seed: { type: float, default: -1 }
    command: >
      PYTHONPATH=$DIOPTRA_PLUGIN_DIR validate-experiment train_on_Fruits360_patched.yml && PYTHONPATH=$DIOPTRA_PLUGIN_DIR run-experiment train_on_Fruits360_patched.yml
      -P data_dir_testing={data_dir_testing}
      -P image_size={image_size}
      -P model_architecture={model_architecture}
      -P epochs={epochs}
      -P batch_size={batch_size}
      -P register_model_name={register_model_name}
      -P learning_rate={learning_rate}
      -P optimizer={optimizer}
      -P validation_split={validation_split}
      -P dataset_run_id_testing={dataset_run_id_testing}
      -P dataset_run_id_training={dataset_run_id_training}
      -P adv_tar_name={adv_tar_name}
      -P adv_data_dir={adv_data_dir}
      -P seed={seed}

  init_model:
    parameters:
      data_dir: { type: path, default: "/dioptra/data/ImageNet-Kaggle-2017/images/ILSVRC/Data/CLS-LOC/val-sorted-1000" }
      image_size: { type: string, default: "[28,28,1]" }
      model_architecture: { type: string, default: "resnet50" }
      batch_size: { type: float, default: 32 }
      register_model_name: { type: string, default: "imagenet_adversarial_patches_pretrained_resnet50" }
      learning_rate: { type: float, default: 0.001 }
      optimizer: { type: string, default: "Adam" }
      imagenet_preprocessing: { type: string, default: "false"}
      seed: { type: float, default: -1 }
    command: >
      PYTHONPATH=$DIOPTRA_PLUGIN_DIR validate-experiment init_model.yml && PYTHONPATH=$DIOPTRA_PLUGIN_DIR run-experiment init_model.yml
      -P data_dir={data_dir}
      -P image_size={image_size}
      -P model_architecture={model_architecture}
      -P batch_size={batch_size}
      -P register_model_name={register_model_name}
      -P learning_rate={learning_rate}
      -P optimizer={optimizer}
      -P imagenet_preprocessing={imagenet_preprocessing}
      -P seed={seed}