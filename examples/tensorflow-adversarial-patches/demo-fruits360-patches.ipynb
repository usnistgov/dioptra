{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Fruits360-VGG16 Patch Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">⚠️ **Warning:** This demo assumes that you have access to an on-prem deployment of Dioptra that provides a copy of the Fruits360 dataset and a CUDA-compatible GPU.\n",
    "> This demo cannot be run on a typical personal computer.\n",
    "\n",
    "This notebook demonstrates the adversarial patch attack applied on the VGG16 model, as well as adversarial training defenses.\n",
    "\n",
    "The following two sections cover experiment setup and is similar across all demos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Experiment Name and Fruits360 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will import the necessary Python modules and ensure the proper environment variables are set so that all the code blocks will work as expected.\n",
    "\n",
    "**Important: Users will need to verify or update the following parameters:**\n",
    "\n",
    "- Ensure that the `USERNAME` parameter is set to your own name.\n",
    "- Ensure that the `DATASET_DIR` parameter is set to the location of the Fruits360 dataset directory. Currently set to `/nfs/data/Fruits360-Kaggle-2019/fruits-360` as the default location.\n",
    "- (Optional) Set the `EXPERIMENT_NAME` parameter to your own preferred experiment name.\n",
    "\n",
    "Other parameters can be modified to alter the RESTful API and MLFlow tracking addresses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages from the Python standard library\n",
    "import os\n",
    "import pprint\n",
    "import time\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "\n",
    "# Filter out warning messages\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Please enter custom username here.\n",
    "USERNAME = \"howard\"\n",
    "\n",
    "# Ensure that the dataset location is properly set here.\n",
    "DATASET_DIR = \"/nfs/data/Fruits360-Kaggle-2019/fruits-360\"\n",
    "\n",
    "# Experiment name (note the username_ prefix convention)\n",
    "EXPERIMENT_NAME = f\"{USERNAME}_fruits360_adversarial_patches\"\n",
    "\n",
    "# Address for connecting the docker container to exposed ports on the host device\n",
    "HOST_DOCKER_INTERNAL = \"host.docker.internal\"\n",
    "# HOST_DOCKER_INTERNAL = \"172.17.0.1\"\n",
    "\n",
    "# Testbed API ports\n",
    "RESTAPI_PORT = \"30080\"\n",
    "MLFLOW_TRACKING_PORT = \"35000\"\n",
    "\n",
    "# Default address for accessing the RESTful API service\n",
    "RESTAPI_ADDRESS = (\n",
    "    f\"http://{HOST_DOCKER_INTERNAL}:{RESTAPI_PORT}\"\n",
    "    if os.getenv(\"IS_JUPYTER_SERVICE\")\n",
    "    else f\"http://localhost:{RESTAPI_PORT}\"\n",
    ")\n",
    "\n",
    "# Override the AI_RESTAPI_URI variable, used to connect to RESTful API service\n",
    "os.environ[\"AI_RESTAPI_URI\"] = RESTAPI_ADDRESS\n",
    "\n",
    "# Default address for accessing the MLFlow Tracking server\n",
    "MLFLOW_TRACKING_URI = (\n",
    "    f\"http://{HOST_DOCKER_INTERNAL}:{MLFLOW_TRACKING_PORT}\"\n",
    "    if os.getenv(\"IS_JUPYTER_SERVICE\")\n",
    "    else f\"http://localhost:{MLFLOW_TRACKING_PORT}\"\n",
    ")\n",
    "\n",
    "# Path to custom task plugins archives\n",
    "CUSTOM_PLUGINS_EVALUATION_TAR_GZ = Path(\"custom-plugins-evaluation.tar.gz\")\n",
    "\n",
    "# Override the MLFLOW_TRACKING_URI variable, used to connect to MLFlow Tracking service\n",
    "os.environ[\"MLFLOW_TRACKING_URI\"] = MLFLOW_TRACKING_URI\n",
    "\n",
    "# Base API address\n",
    "RESTAPI_API_BASE = f\"{RESTAPI_ADDRESS}/api\"\n",
    "\n",
    "# Path to workflows archive\n",
    "WORKFLOWS_TAR_GZ = Path(\"workflows.tar.gz\")\n",
    "\n",
    "# Import third-party Python packages\n",
    "import numpy as np\n",
    "import requests\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# Import utils.py file\n",
    "import utils\n",
    "\n",
    "# Create random number generator\n",
    "rng = np.random.default_rng(54399264723942495723666216079516778448)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training and testing images in this directory are saved as JPEG files and are organized into the following folder structure:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    fruits360\n",
    "    ├── Test\n",
    "    │   ├── Apple Braeburn\n",
    "    │   ├── Apple Crimson Snow\n",
    "    │   ├── Apple Golden 1\n",
    "    │   ├── Apple Golden 2\n",
    "    │   ├── Apple Golden 3\n",
    "    │   ├── ...\n",
    "    │   └── Walnut\n",
    "    ├── Training\n",
    "    │   ├── Apple Braeburn\n",
    "    │   ├── Apple Crimson Snow\n",
    "    │   ├── Apple Golden 1\n",
    "    │   ├── Apple Golden 2\n",
    "    │   ├── Apple Golden 3\n",
    "    │   ├── ...\n",
    "    │   └── Walnut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The subfolders under `fruits360/Training/` and `fruits360/Test` are the classification labels for the images in the dataset.\n",
    "There are 120 labels or subfolders for the training and test sets.\n",
    "This folder structure is a standardized way to encode the label information and many libraries can make use of it, including the Tensorflow library that we are using for this particular demo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit and run jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entrypoints that we will be running in this example are implemented in the Python source files under `src/` and the `MLproject` file.\n",
    "To run these entrypoints within the testbed architecture, we need to package those files up into an archive and submit it to the Testbed RESTful API to create a new job.\n",
    "For convenience, the `Makefile` provides a rule for creating the archive file for this example, just run `make workflows`,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tar  -czf workflows.tar.gz src/gaussian_augmentation.py src/deploy_patch.py src/init_model.py src/defenses_image_preprocessing.py src/tasks.py src/train.py src/import_keras.py src/spatial_smoothing.py src/generate_patch.py src/jpeg_compression.py src/attacks_patch_updated.py src/fgm.py src/infer.py src/registry_art_updated.py src/estimators_keras_classifiers_updated.py src/data_tensorflow_updated.py MLproject\n",
      "chmod 644 workflows.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hhuang/.conda/envs/tensorflow-mnist-classifier/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Create the workflows.tar.gz file\n",
    "make workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To connect with the endpoint, we will use a client class defined in the `utils.py` file that is able to connect with the Testbed RESTful API using the HTTP protocol.\n",
    "We connect using the client below, which uses the environment variable `AI_RESTAPI_URI` to figure out how to connect to the Testbed RESTful API,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hhuang/.conda/envs/tensorflow-mnist-classifier/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "restapi_client = utils.SecuringAIClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to register an experiment under which to collect our job runs.\n",
    "The code below checks if the relevant experiment exists.\n",
    "If it does, then it just returns info about the experiment, if it doesn't, it then registers the new experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'createdOn': '2020-11-05T09:37:19.652250',\n",
       " 'experimentId': 11,\n",
       " 'lastModified': '2020-11-05T09:37:19.652250',\n",
       " 'name': 'howard_fruits360_adversarial_patches'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_experiment = restapi_client.get_experiment_by_name(name=EXPERIMENT_NAME)\n",
    "\n",
    "if response_experiment is None or \"Not Found\" in response_experiment.get(\"message\", []):\n",
    "    response_experiment = restapi_client.register_experiment(name=EXPERIMENT_NAME)\n",
    "\n",
    "response_experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should also check which queues are available for running our jobs to make sure that the resources that we need are available.\n",
    "The code below queries the Testbed API and returns a list of active queues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'createdOn': '2020-11-20T17:46:06.756687',\n",
       "  'queueId': 1,\n",
       "  'lastModified': '2020-11-20T17:46:06.756687',\n",
       "  'name': 'tensorflow_cpu'},\n",
       " {'createdOn': '2020-11-20T18:00:40.876888',\n",
       "  'queueId': 2,\n",
       "  'lastModified': '2020-11-20T18:00:40.876888',\n",
       "  'name': 'tensorflow_gpu'},\n",
       " {'createdOn': '2020-11-20T19:52:36.079781',\n",
       "  'queueId': 5,\n",
       "  'lastModified': '2020-11-20T19:52:36.079781',\n",
       "  'name': 'pytorch_cpu'},\n",
       " {'createdOn': '2020-11-20T19:52:43.348460',\n",
       "  'queueId': 7,\n",
       "  'lastModified': '2020-11-20T19:52:43.348460',\n",
       "  'name': 'pytorch_gpu'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restapi_client.list_queues()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example also makes use of the `custom_patch_plugins` custom task plugin package stored locally under the `task-plugins/securingai_custom/custom_patch_plugins` directory.\n",
    "To register these custom task plugins, we first need to package them up into an archive.\n",
    "For convenience, the `Makefile` provides a rule for creating the custom task plugins archive file, just run `make custom-plugins`,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tar -C task-plugins/securingai_custom -czf custom-plugins-evaluation.tar.gz custom_patch_plugins/defenses_image_preprocessing.py custom_patch_plugins/tensorflow.py custom_patch_plugins/import_keras.py custom_patch_plugins/__init__.py custom_patch_plugins/attacks_patch.py custom_patch_plugins/registry_art.py custom_patch_plugins/estimators_keras_classifiers.py custom_patch_plugins/data_tensorflow.py\n",
      "chmod 644 custom-plugins-evaluation.tar.gz\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Create the workflows.tar.gz file\n",
    "make custom-plugins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the custom task plugin package is packaged into an archive file, next we register it by uploading the file to the REST API.\n",
    "Note that we need to provide the name to use for custom task plugin package, this name must be unique under the custom task plugins namespace.\n",
    "For a full list of the custom task plugins, use `restapi_client.restapi_client.list_custom_task_plugins()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hhuang/.conda/envs/tensorflow-mnist-classifier/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'taskPluginName': 'custom_patch_plugins',\n",
       " 'collection': 'securingai_custom',\n",
       " 'modules': ['data_tensorflow.py',\n",
       "  'tensorflow.py',\n",
       "  'attacks_patch.py',\n",
       "  'registry_art.py',\n",
       "  '__init__.py',\n",
       "  'estimators_keras_classifiers.py',\n",
       "  'import_keras.py',\n",
       "  'defenses_image_preprocessing.py']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restapi_client.delete_custom_task_plugin(name=\"custom_patch_plugins\")\n",
    "response_custom_plugins = restapi_client.get_custom_task_plugin(name=\"custom_patch_plugins\")\n",
    "\n",
    "if response_custom_plugins is None or \"Not Found\" in response_custom_plugins.get(\"message\", []):\n",
    "    response_custom_plugins = restapi_client.upload_custom_plugin_package(\n",
    "        custom_plugin_name=\"custom_patch_plugins\",\n",
    "        custom_plugin_file=CUSTOM_PLUGINS_EVALUATION_TAR_GZ,\n",
    "    )\n",
    "\n",
    "response_custom_plugins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If at any point you need to update one or more files within the `evaluation` plugin package, you will need to unregister/delete the custom task plugin first using the REST API.\n",
    "This can be done as follows,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Delete the 'evaluation' custom task plugin package\n",
    "restapi_client.delete_custom_task_plugin(name=\"custom_patch_plugins\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Patches: Baseline Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will train our baseline VGG16 model on the Fruits360 dataset. \n",
    "We will be submitting our jobs to the `\"tensorflow_gpu\"` queue.\n",
    "Once the experiment is finished, we will examine the accuracy results of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training job for VGG16 neural network submitted\n",
      "\n",
      "{'createdOn': '2021-09-23T07:10:28.929177',\n",
      " 'dependsOn': None,\n",
      " 'entryPoint': 'train',\n",
      " 'entryPointKwargs': '-P batch_size=20 -P '\n",
      "                     'register_model_name=howard_fruits360_adversarial_patches_vgg16 '\n",
      "                     '-P image_size=224,224,3 -P model_architecture=vgg16 -P '\n",
      "                     'epochs=30 -P '\n",
      "                     'data_dir_training=/nfs/data/Fruits360-Kaggle-2019/fruits-360/Training '\n",
      "                     '-P '\n",
      "                     'data_dir_testing=/nfs/data/Fruits360-Kaggle-2019/fruits-360/Test',\n",
      " 'experimentId': 11,\n",
      " 'jobId': '51c81f39-3bc6-45a3-a56a-1fb0e8482bf0',\n",
      " 'lastModified': '2021-09-23T07:10:28.929177',\n",
      " 'mlflowRunId': None,\n",
      " 'queueId': 2,\n",
      " 'status': 'queued',\n",
      " 'timeout': '1h',\n",
      " 'workflowUri': 's3://workflow/dd3fb6d4ce3a49d2bb86f7d431515494/workflows.tar.gz'}\n"
     ]
    }
   ],
   "source": [
    "response_vgg16_train = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"train\",\n",
    "    entry_point_kwargs=\" \".join([\n",
    "        \"-P batch_size=20\",\n",
    "        f\"-P register_model_name={EXPERIMENT_NAME}_vgg16\",\n",
    "        \"-P image_size=224,224,3\",\n",
    "        \"-P model_architecture=vgg16\",\n",
    "        \"-P epochs=30\",\n",
    "        f\"-P data_dir_training={DATASET_DIR}/Training\",\n",
    "        f\"-P data_dir_testing={DATASET_DIR}/Test\",\n",
    "    ]),\n",
    "    queue=\"tensorflow_gpu\",\n",
    "    timeout=\"1h\",\n",
    ")\n",
    "\n",
    "print(\"Training job for VGG16 neural network submitted\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_vgg16_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following helper functions will recheck the job responses until the job is completed or a run ID is available. \n",
    "The run ID is needed to link dependencies between jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlflow_run_id_is_not_known(job_response):\n",
    "    return job_response[\"mlflowRunId\"] is None and job_response[\"status\"] not in [\n",
    "        \"failed\",\n",
    "        \"finished\",\n",
    "    ]\n",
    "\n",
    "\n",
    "def get_run_id(job_response):\n",
    "    while mlflow_run_id_is_not_known(job_response):\n",
    "        time.sleep(1)\n",
    "        job_response = restapi_client.get_job_by_id(job_response[\"jobId\"])\n",
    "        \n",
    "    return job_response\n",
    "\n",
    "\n",
    "def wait_until_finished(job_response):\n",
    "    # First make sure job has started.\n",
    "    job_response = get_run_id(job_response)\n",
    "    \n",
    "    # Next re-check job until it has stopped running.\n",
    "    while (job_response[\"status\"] not in [\"failed\", \"finished\"]):\n",
    "        time.sleep(1)\n",
    "        job_response = restapi_client.get_job_by_id(job_response[\"jobId\"])\n",
    "    \n",
    "    return job_response    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now wait for the job to complete before proceeding to next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training job for VGG16 neural network\n",
      "{'createdOn': '2021-09-23T07:10:28.929177',\n",
      " 'dependsOn': None,\n",
      " 'entryPoint': 'train',\n",
      " 'entryPointKwargs': '-P batch_size=20 -P '\n",
      "                     'register_model_name=howard_fruits360_adversarial_patches_vgg16 '\n",
      "                     '-P image_size=224,224,3 -P model_architecture=vgg16 -P '\n",
      "                     'epochs=30 -P '\n",
      "                     'data_dir_training=/nfs/data/Fruits360-Kaggle-2019/fruits-360/Training '\n",
      "                     '-P '\n",
      "                     'data_dir_testing=/nfs/data/Fruits360-Kaggle-2019/fruits-360/Test',\n",
      " 'experimentId': 11,\n",
      " 'jobId': '51c81f39-3bc6-45a3-a56a-1fb0e8482bf0',\n",
      " 'lastModified': '2021-09-23T07:46:19.640608',\n",
      " 'mlflowRunId': '67b9313763544c41a69a8ff83e1c3231',\n",
      " 'queueId': 2,\n",
      " 'status': 'finished',\n",
      " 'timeout': '1h',\n",
      " 'workflowUri': 's3://workflow/dd3fb6d4ce3a49d2bb86f7d431515494/workflows.tar.gz'}\n"
     ]
    }
   ],
   "source": [
    "response_vgg16_train = wait_until_finished(response_vgg16_train)\n",
    "print(\"Training job for VGG16 neural network\")\n",
    "pprint.pprint(response_vgg16_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking baseline VGG16 job accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the job has finished running we can view the results either through the MLflow URI or by accessing the job via MLflow client.\n",
    "Here we will show the baseline accuracy results from the previous training job.\n",
    "Please see [Querying the MLFlow Tracking Service](#Querying-the-MLFlow-Tracking-Service) section for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.9973983764648438,\n",
      " 'auc': 0.9998854994773865,\n",
      " 'loss': 0.009346200119934173,\n",
      " 'precision': 0.9976862668991089,\n",
      " 'recall': 0.9971712231636047,\n",
      " 'restored_epoch': 7.0,\n",
      " 'stopped_epoch': 12.0,\n",
      " 'training_time_in_minutes': 27.08974365,\n",
      " 'val_accuracy': 0.9858291149139404,\n",
      " 'val_auc': 0.9999104142189026,\n",
      " 'val_loss': 0.039089418488949965,\n",
      " 'val_precision': 0.9875176548957825,\n",
      " 'val_recall': 0.9834258556365967}\n"
     ]
    }
   ],
   "source": [
    "# Helper function for viewing MLflow results.\n",
    "def get_mlflow_results(job_response):\n",
    "    mlflow_client = MlflowClient()\n",
    "    job_response = wait_until_finished(job_response)\n",
    "    \n",
    "    if(job_response['status']==\"failed\"):\n",
    "        return {}\n",
    "    \n",
    "    run = mlflow_client.get_run(job_response[\"mlflowRunId\"])  \n",
    "    \n",
    "    while(len(run.data.metrics) == 0):\n",
    "        time.sleep(1)\n",
    "        run = mlflow_client.get_run(job_response[\"mlflowRunId\"])\n",
    "        \n",
    "    return run\n",
    "\n",
    "\n",
    "results = get_mlflow_results(response_vgg16_train)\n",
    "pprint.pprint(results.data.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying and Testing Adversarial Patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create and apply the adversarial patches over our test set and evaluate the performance of the baseline model on the adversarial patches.\n",
    "We will also apply the patches over the training set for the adversarial training defense evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patch Generation\n",
    "\n",
    "The following job will generate the adversarial patches. \n",
    "Feel free to adjust the input parameters to see how they impact the effectiveness of the patch attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patch attack (VGG16 architecture) job submitted\n",
      "\n",
      "{'createdOn': '2021-09-23T07:46:20.062639',\n",
      " 'dependsOn': '51c81f39-3bc6-45a3-a56a-1fb0e8482bf0',\n",
      " 'entryPoint': 'gen_patch',\n",
      " 'entryPointKwargs': '-P model_name=howard_fruits360_adversarial_patches_vgg16 '\n",
      "                     '-P model_version=none -P image_size=224,224,3 -P '\n",
      "                     'imagenet_preprocessing=True -P '\n",
      "                     'data_dir=/nfs/data/Fruits360-Kaggle-2019/fruits-360/Training '\n",
      "                     '-P num_patch_gen_samples=20 -P num_patch=1 -P '\n",
      "                     'patch_target=5',\n",
      " 'experimentId': 11,\n",
      " 'jobId': '53cdc2a3-f270-41d7-ad97-d284ef262400',\n",
      " 'lastModified': '2021-09-23T07:46:20.062639',\n",
      " 'mlflowRunId': None,\n",
      " 'queueId': 2,\n",
      " 'status': 'queued',\n",
      " 'timeout': '24h',\n",
      " 'workflowUri': 's3://workflow/7943a68e20bd4608ad9c95fdbb70fac8/workflows.tar.gz'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create Patches\n",
    "response_vgg16_patches = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"gen_patch\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P model_name={EXPERIMENT_NAME}_vgg16\",\n",
    "            f\"-P model_version=none\",\n",
    "            \"-P image_size=224,224,3\",\n",
    "            \"-P imagenet_preprocessing=True\",\n",
    "            f\"-P data_dir={DATASET_DIR}/Training\",\n",
    "            \"-P num_patch_gen_samples=20\",\n",
    "            \"-P num_patch=1\",\n",
    "            \"-P patch_target=5\"\n",
    "        ]\n",
    "    ),\n",
    "    queue=\"tensorflow_gpu\",\n",
    "    depends_on=response_vgg16_train[\"jobId\"],\n",
    ")\n",
    "\n",
    "print(\"Patch attack (VGG16 architecture) job submitted\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_vgg16_patches)\n",
    "print(\"\")\n",
    "\n",
    "response_vgg16_patches = get_run_id(response_vgg16_patches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploying and Testing Adversarial Patches\n",
    "\n",
    "Now we will apply the adversarial patches over our test set and evaluate the performance of the baseline model on the adversarial patches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patch deployment (VGG16 architecture) job submitted\n",
      "\n",
      "{'createdOn': '2021-09-23T07:46:27.236806',\n",
      " 'dependsOn': '53cdc2a3-f270-41d7-ad97-d284ef262400',\n",
      " 'entryPoint': 'deploy_patch',\n",
      " 'entryPointKwargs': '-P run_id=b26a5781c6a146ce86930630043b605a -P '\n",
      "                     'model_name=howard_fruits360_adversarial_patches_vgg16 -P '\n",
      "                     'model_version=none -P image_size=224,224,3 -P '\n",
      "                     'imagenet_preprocessing=True -P '\n",
      "                     'data_dir=/nfs/data/Fruits360-Kaggle-2019/fruits-360/Training',\n",
      " 'experimentId': 11,\n",
      " 'jobId': 'c5943e33-7704-4192-9684-421f9e80cf70',\n",
      " 'lastModified': '2021-09-23T07:46:27.236806',\n",
      " 'mlflowRunId': None,\n",
      " 'queueId': 2,\n",
      " 'status': 'queued',\n",
      " 'timeout': '24h',\n",
      " 'workflowUri': 's3://workflow/0a12c24ae0004c698f5fed581084d0e1/workflows.tar.gz'}\n",
      "\n",
      "Patch deployment (VGG16 architecture) job submitted\n",
      "\n",
      "{'createdOn': '2021-09-23T07:59:24.352161',\n",
      " 'dependsOn': '53cdc2a3-f270-41d7-ad97-d284ef262400',\n",
      " 'entryPoint': 'deploy_patch',\n",
      " 'entryPointKwargs': '-P run_id=b26a5781c6a146ce86930630043b605a -P '\n",
      "                     'model_name=howard_fruits360_adversarial_patches_vgg16 -P '\n",
      "                     'model_version=none -P image_size=224,224,3 -P '\n",
      "                     'imagenet_preprocessing=True -P '\n",
      "                     'data_dir=/nfs/data/Fruits360-Kaggle-2019/fruits-360/Test '\n",
      "                     '-P patch_deployment_method=corrupt',\n",
      " 'experimentId': 11,\n",
      " 'jobId': '5141a991-e001-4215-adec-01022563935d',\n",
      " 'lastModified': '2021-09-23T07:59:24.352161',\n",
      " 'mlflowRunId': None,\n",
      " 'queueId': 2,\n",
      " 'status': 'queued',\n",
      " 'timeout': '24h',\n",
      " 'workflowUri': 's3://workflow/f7ace98161b14d69b18f2f614b958485/workflows.tar.gz'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Deploy Patch attack on training set.\n",
    "response_deploy_vgg16_patches_training = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"deploy_patch\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={response_vgg16_patches['mlflowRunId']}\",\n",
    "            f\"-P model_name={EXPERIMENT_NAME}_vgg16\",\n",
    "            f\"-P model_version=none\",\n",
    "            \"-P image_size=224,224,3\",\n",
    "            \"-P imagenet_preprocessing=True\",\n",
    "            f\"-P data_dir={DATASET_DIR}/Training\",\n",
    "        ]\n",
    "    ),\n",
    "    queue=\"tensorflow_gpu\",\n",
    "    depends_on=response_vgg16_patches[\"jobId\"],\n",
    ")\n",
    "\n",
    "print(\"Patch deployment (VGG16 architecture) job submitted\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_deploy_vgg16_patches_training)\n",
    "print(\"\")\n",
    "\n",
    "response_deploy_vgg16_patches_training = get_run_id(response_deploy_vgg16_patches_training)\n",
    "\n",
    "    \n",
    "# Deploy Patch attack on test set.\n",
    "response_deploy_vgg16_patches_testing = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"deploy_patch\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={response_vgg16_patches['mlflowRunId']}\",\n",
    "            f\"-P model_name={EXPERIMENT_NAME}_vgg16\",\n",
    "            f\"-P model_version=none\",\n",
    "            \"-P image_size=224,224,3\",\n",
    "            \"-P imagenet_preprocessing=True\",\n",
    "            f\"-P data_dir={DATASET_DIR}/Test\",\n",
    "            \"-P patch_deployment_method=corrupt\"\n",
    "        ]\n",
    "    ),\n",
    "    queue=\"tensorflow_gpu\",\n",
    "    depends_on=response_vgg16_patches[\"jobId\"],\n",
    ")\n",
    "\n",
    "print(\"Patch deployment (VGG16 architecture) job submitted\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_deploy_vgg16_patches_testing)\n",
    "print(\"\")\n",
    "\n",
    "response_deploy_vgg16_patches_testing = get_run_id(response_deploy_vgg16_patches_testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patch Attack Evaluation: Baseline VGG16 Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will run an inference step to check the patch-attacked dataset with our VGG16-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patch evaluation (VGG16 architecture) job submitted\n",
      "\n",
      "{'createdOn': '2021-09-23T07:59:31.531198',\n",
      " 'dependsOn': '5141a991-e001-4215-adec-01022563935d',\n",
      " 'entryPoint': 'infer',\n",
      " 'entryPointKwargs': '-P run_id=f0b0dd21de8d4f39b9c1740f74a03164 -P '\n",
      "                     'model_name=howard_fruits360_adversarial_patches_vgg16 -P '\n",
      "                     'model_version=none -P image_size=224,224,3 -P '\n",
      "                     'imagenet_preprocessing=True -P '\n",
      "                     'adv_tar_name=adversarial_patch_dataset.tar.gz -P '\n",
      "                     'adv_data_dir=adv_patch_dataset -P batch_size=512',\n",
      " 'experimentId': 11,\n",
      " 'jobId': 'eef453e0-0a2d-40af-91c9-c14c6fd51538',\n",
      " 'lastModified': '2021-09-23T07:59:31.531198',\n",
      " 'mlflowRunId': None,\n",
      " 'queueId': 2,\n",
      " 'status': 'queued',\n",
      " 'timeout': '24h',\n",
      " 'workflowUri': 's3://workflow/f875df0a995642099bf5403728c5f6e4/workflows.tar.gz'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check patched dataset results   \n",
    "response_infer_vgg16_patch = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"infer\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={response_deploy_vgg16_patches_testing['mlflowRunId']}\",\n",
    "            f\"-P model_name={EXPERIMENT_NAME}_vgg16\",\n",
    "            f\"-P model_version=none\",\n",
    "            \"-P image_size=224,224,3\",\n",
    "            \"-P imagenet_preprocessing=True\",\n",
    "            \"-P adv_tar_name=adversarial_patch_dataset.tar.gz\",\n",
    "            \"-P adv_data_dir=adv_patch_dataset\",\n",
    "            \"-P batch_size=512\",\n",
    "        ]\n",
    "    ),\n",
    "    queue=\"tensorflow_gpu\",\n",
    "    depends_on=response_deploy_vgg16_patches_testing[\"jobId\"],\n",
    ")\n",
    "\n",
    "print(\"Patch evaluation (VGG16 architecture) job submitted\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_infer_vgg16_patch)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline model results on adversarially patched dataset: \n",
      "{'accuracy': 0.020526008680462837,\n",
      " 'auc': 0.506244421005249,\n",
      " 'loss': 1675.0153272675304,\n",
      " 'precision': 0.020528001710772514,\n",
      " 'recall': 0.020526008680462837}\n"
     ]
    }
   ],
   "source": [
    "# Wait for the job to finish\n",
    "response_infer_vgg16_patch = wait_until_finished(response_infer_vgg16_patch)\n",
    "\n",
    "# Check on the patch evaluation results\n",
    "results = get_mlflow_results(response_infer_vgg16_patch)\n",
    "print(\"Baseline model results on adversarially patched dataset: \")\n",
    "pprint.pprint(results.data.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We can see that the adversarial patch attack causes a noticeable decrease in the model's accuracy scores.\n",
    "\n",
    "We will now test various defenses against the patch attacked images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defense: Adversarial Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next part of the adversarial patch demo focuses on investigating effective defenses against the attack."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adversarial Training Defense\n",
    "\n",
    "We will train a new copy of the VGG16 model on training set that contains adversarial patches.\n",
    "In doing so, the model learns to ignore the adversarial patches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patch adversarial training (VGG16 architecture) job submitted\n",
      "\n",
      "{'createdOn': '2021-09-23T08:33:10.370580',\n",
      " 'dependsOn': 'c5943e33-7704-4192-9684-421f9e80cf70',\n",
      " 'entryPoint': 'train',\n",
      " 'entryPointKwargs': '-P '\n",
      "                     'dataset_run_id_testing=f0b0dd21de8d4f39b9c1740f74a03164 '\n",
      "                     '-P '\n",
      "                     'dataset_run_id_training=f434549a4826479aa62e16de9a19b0bb '\n",
      "                     '-P batch_size=256 -P '\n",
      "                     'register_model_name=howard_fruits360_adversarial_patches_vgg16 '\n",
      "                     '-P image_size=224,224,3 -P imagenet_preprocessing=True '\n",
      "                     '-P epochs=10 -P '\n",
      "                     'data_dir_training=/nfs/data/Fruits360-Kaggle-2019/fruits-360/Training '\n",
      "                     '-P '\n",
      "                     'data_dir_testing=/nfs/data/Fruits360-Kaggle-2019/fruits-360/Test '\n",
      "                     '-P load_dataset_from_mlruns=True',\n",
      " 'experimentId': 11,\n",
      " 'jobId': 'ac37d682-a51c-4d6c-9555-a9c655705449',\n",
      " 'lastModified': '2021-09-23T08:33:10.370580',\n",
      " 'mlflowRunId': None,\n",
      " 'queueId': 2,\n",
      " 'status': 'queued',\n",
      " 'timeout': '24h',\n",
      " 'workflowUri': 's3://workflow/6b29b340acea49b58570e51c89ffe6b6/workflows.tar.gz'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response_patches_adv_training = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"train\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P dataset_run_id_testing={response_deploy_vgg16_patches_testing['mlflowRunId']}\",\n",
    "            f\"-P dataset_run_id_training={response_deploy_vgg16_patches_training['mlflowRunId']}\",\n",
    "            \"-P batch_size=256\",\n",
    "            f\"-P register_model_name={EXPERIMENT_NAME}_vgg16\",\n",
    "            \"-P image_size=224,224,3\",\n",
    "            \"-P imagenet_preprocessing=True\",\n",
    "            \"-P epochs=10\",\n",
    "            f\"-P data_dir_training={DATASET_DIR}/Training\",\n",
    "            f\"-P data_dir_testing={DATASET_DIR}/Test\",\n",
    "            \"-P load_dataset_from_mlruns=True\",\n",
    "            \n",
    "        ]\n",
    "    ),\n",
    "    queue=\"tensorflow_gpu\",\n",
    "    depends_on=response_deploy_vgg16_patches_training[\"jobId\"],\n",
    ")\n",
    "\n",
    "print(\"Patch adversarial training (VGG16 architecture) job submitted\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_patches_adv_training)\n",
    "print(\"\")\n",
    "\n",
    "response_patches_adv_training = get_run_id(response_patches_adv_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patch evaluation job submitted\n",
      "\n",
      "{'createdOn': '2021-09-23T09:38:29.239228',\n",
      " 'dependsOn': 'ac37d682-a51c-4d6c-9555-a9c655705449',\n",
      " 'entryPoint': 'infer',\n",
      " 'entryPointKwargs': '-P run_id=f0b0dd21de8d4f39b9c1740f74a03164 -P '\n",
      "                     'model_name=howard_fruits360_adversarial_patches_adversarial_patch_vgg16 '\n",
      "                     '-P model_version=none -P image_size=224,224,3 -P '\n",
      "                     'imagenet_preprocessing=True -P batch_size=256 -P '\n",
      "                     'adv_tar_name=adversarial_patch_dataset.tar.gz -P '\n",
      "                     'adv_data_dir=adv_patch_dataset',\n",
      " 'experimentId': 11,\n",
      " 'jobId': '88fd081e-375f-49b0-b4ea-9a4885631fc9',\n",
      " 'lastModified': '2021-09-23T09:38:29.239228',\n",
      " 'mlflowRunId': None,\n",
      " 'queueId': 2,\n",
      " 'status': 'queued',\n",
      " 'timeout': '24h',\n",
      " 'workflowUri': 's3://workflow/0f1feff5139a42cda467f84b41ad696a/workflows.tar.gz'}\n",
      "\n",
      "Adversarial Training Results:\n",
      "{'accuracy': 0.1825989931821823,\n",
      " 'auc': 0.668190598487854,\n",
      " 'fn': 16890.0,\n",
      " 'fp': 16649.0,\n",
      " 'loss': 9.6808679604236,\n",
      " 'precision': 0.18255020678043365,\n",
      " 'recall': 0.18041537702083588,\n",
      " 'tn': 2435703.0,\n",
      " 'tp': 3718.0}\n"
     ]
    }
   ],
   "source": [
    "response_evaluate_adv_training = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"infer\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={response_deploy_vgg16_patches_testing['mlflowRunId']}\",\n",
    "            f\"-P model_name={EXPERIMENT_NAME}_adversarial_patch_vgg16\",\n",
    "            f\"-P model_version=none\",\n",
    "            \"-P image_size=224,224,3\",\n",
    "            \"-P imagenet_preprocessing=True\",\n",
    "            \"-P batch_size=256\",\n",
    "            \"-P adv_tar_name=adversarial_patch_dataset.tar.gz\",\n",
    "            \"-P adv_data_dir=adv_patch_dataset\",\n",
    "        ]\n",
    "    ),\n",
    "    queue=\"tensorflow_gpu\",\n",
    "    depends_on=response_patches_adv_training[\"jobId\"],\n",
    ")\n",
    "\n",
    "print(\"Patch evaluation job submitted\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_evaluate_adv_training)\n",
    "print(\"\")\n",
    "\n",
    "response_patches_adv_training= wait_until_finished(response_evaluate_adv_training)\n",
    "results = get_mlflow_results(response_patches_adv_training)\n",
    "print(\"Adversarial Training Results:\")\n",
    "pprint.pprint(results.data.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying the MLFlow Tracking Service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently the lab API can only be used to register experiments and start jobs, so if users wish to extract their results programmatically, they can use the `MlflowClient()` class from the `mlflow` Python package to connect and query their results.\n",
    "Since we captured the run ids generated by MLFlow, we can easily retrieve the data logged about one of our jobs and inspect the results.\n",
    "To start the client, we simply need to run,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_client = MlflowClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The client uses the environment variable `MLFLOW_TRACKING_URI` to figure out how to connect to the MLFlow Tracking Service, which we configured near the top of this notebook.\n",
    "To query the results of one of our runs, we just need to pass the run id to the client's `get_run()` method.\n",
    "As an example, let's query the run results for the patch attack applied to the VGG16 architecture,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_adv_patches = mlflow_client.get_run(response_patches_adv_training[\"mlflowRunId\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the request completed successfully, we should now be able to query data collected during the run.\n",
    "For example, to review the collected metrics, we just use,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.1825989931821823,\n",
      " 'auc': 0.668190598487854,\n",
      " 'fn': 16890.0,\n",
      " 'fp': 16649.0,\n",
      " 'loss': 9.6808679604236,\n",
      " 'precision': 0.18255020678043365,\n",
      " 'recall': 0.18041537702083588,\n",
      " 'tn': 2435703.0,\n",
      " 'tp': 3718.0}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(run_adv_patches.data.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To review the run's parameters, we use,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'adv_data_dir': 'adv_patch_dataset',\n",
      " 'adv_tar_name': 'adversarial_patch_dataset.tar.gz',\n",
      " 'batch_size': '256',\n",
      " 'dataset_seed': '390581924',\n",
      " 'entry_point_seed': '323551244237149393329878256906325458072',\n",
      " 'image_size': '224,224,3',\n",
      " 'imagenet_preprocessing': 'True',\n",
      " 'model_name': 'howard_fruits360_adversarial_patches_adversarial_patch_vgg16',\n",
      " 'model_version': 'none',\n",
      " 'run_id': 'f0b0dd21de8d4f39b9c1740f74a03164',\n",
      " 'seed': '-1',\n",
      " 'tensorflow_global_seed': '958933669'}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(run_adv_patches.data.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To review the run's tags, we use,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mlflow.project.backend': 'securingai',\n",
      " 'mlflow.project.entryPoint': 'infer',\n",
      " 'mlflow.source.name': '/work/tmp3831s6vz',\n",
      " 'mlflow.source.type': 'PROJECT',\n",
      " 'mlflow.user': 'securingai',\n",
      " 'securingai.dependsOn': 'ac37d682-a51c-4d6c-9555-a9c655705449',\n",
      " 'securingai.jobId': '88fd081e-375f-49b0-b4ea-9a4885631fc9',\n",
      " 'securingai.queue': 'tensorflow_gpu'}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(run_adv_patches.data.tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many things you can query using the MLFlow client.\n",
    "[The MLFlow documentation gives a full overview of the methods that are available](https://www.mlflow.org/docs/latest/python_api/mlflow.tracking.html#mlflow.tracking.MlflowClient)."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "edee40310913f16e2ca02c1d37887bcb7f07f00399ca119bb7e27de7d632ea99"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
