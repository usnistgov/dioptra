{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow MNIST Classifier demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains an end-to-end demostration of Dioptra that can be run on any modern laptop.\n",
    "Please see the [example README](README.md) for instructions on how to prepare your environment for running this example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we import the necessary Python modules and ensure the proper environment variables are set so that all the code blocks will work as expected,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = \"mnist_fgm\"\n",
    "EXPERIMENT_DESC = \"applying the fast gradient sign (FGM) attack to a classifier trained on MNIST\"\n",
    "QUEUE_NAME = 'tensorflow_cpu'\n",
    "QUEUE_DESC = 'Tensorflow CPU Queue'\n",
    "MODEL_NAME = \"mnist_classifier\"\n",
    "\n",
    "# Default address for accessing the RESTful API service\n",
    "RESTAPI_ADDRESS = \"http://localhost\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages from the Python standard library\n",
    "import json\n",
    "import os\n",
    "import pprint\n",
    "import time\n",
    "import warnings\n",
    "from IPython.display import display, clear_output\n",
    "import logging\n",
    "import structlog\n",
    "from pathlib import Path\n",
    "\n",
    "# Filter out warning messages\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "structlog.configure(\n",
    "    wrapper_class=structlog.make_filtering_bound_logger(logging.ERROR),\n",
    ")\n",
    "\n",
    "from dioptra.client import connect_json_dioptra_client, connect_response_dioptra_client, select_files_in_directory, select_one_or_more_files\n",
    "\n",
    "def wait_for_job(job, job_name, quiet=False):\n",
    "    n = 0\n",
    "    while job['status'] not in ['finished', 'failed']:\n",
    "        job = client.jobs.get_by_id(job['id'])\n",
    "        time.sleep(1)\n",
    "        if not quiet:\n",
    "            clear_output(wait=True)\n",
    "            display(\"Waiting for job.\" + \".\" * (n % 3) )\n",
    "        n += 1\n",
    "    if not quiet:\n",
    "        if job['status'] == 'finished':\n",
    "            clear_output(wait=True)\n",
    "            display(f'Job finished. Started \"{job_name}\" job.')\n",
    "        else:\n",
    "            raise Exception(\"Previous job failed. Please see tensorflow-cpu logs for details.\")\n",
    "    return job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtained a copy of the MNIST dataset when we ran `download_data.py` script. If you have not done so already, see [How to Obtain Common Datasets](https://pages.nist.gov/dioptra/getting-started/acquiring-datasets.html).\n",
    "The training and testing images for the MNIST dataset are stored within the `/dioptra/data/Mnist` directory as PNG files that are organized into the following folder structure,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Mnist\n",
    "    ├── testing\n",
    "    │   ├── 0\n",
    "    │   ├── 1\n",
    "    │   ├── 2\n",
    "    │   ├── 3\n",
    "    │   ├── 4\n",
    "    │   ├── 5\n",
    "    │   ├── 6\n",
    "    │   ├── 7\n",
    "    │   ├── 8\n",
    "    │   └── 9\n",
    "    └── training\n",
    "        ├── 0\n",
    "        ├── 1\n",
    "        ├── 2\n",
    "        ├── 3\n",
    "        ├── 4\n",
    "        ├── 5\n",
    "        ├── 6\n",
    "        ├── 7\n",
    "        ├── 8\n",
    "        └── 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The subfolders under `training/` and `testing/` are the classification labels for the images in the dataset.\n",
    "This folder structure is a standardized way to encode the label information and many libraries can make use of it, including the Tensorflow library that we are using for this particular demo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Login to Dioptra and setup RESTAPI client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To connect with the endpoint, we will use a client class defined in the `examples/scripts/client.py` file that is able to connect with the Dioptra RESTful API using the HTTP protocol.\n",
    "We connect using the client below.\n",
    "The client uses the environment variable `DIOPTRA_RESTAPI_URI`, which we configured at the top of the notebook, to figure out how to connect to the Dioptra RESTful API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#client = connect_response_dioptra_client()\n",
    "client = connect_json_dioptra_client(address=RESTAPI_ADDRESS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is necessary to login to the RESTAPI to be able to perform any functions. Here we create a user if it is not created already, and login with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    client.users.create(\n",
    "        username='pluginuser2',\n",
    "        email='pluginuser2@dioptra.nccoe.nist.gov',\n",
    "        password='pleasemakesuretoPLUGINthecomputer'\n",
    "    )\n",
    "except:\n",
    "    pass # ignore if user exists already\n",
    "\n",
    "client.auth.login(\n",
    "    username='pluginuser2',\n",
    "    password='pleasemakesuretoPLUGINthecomputer'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload all the entrypoints in the src/ folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import from local filesystem\n",
    "\n",
    "response = client.workflows.import_resources(group_id=1,\n",
    "                                             source=select_files_in_directory(\"../extra/\", recursive=True),\n",
    "                                             config_path=\"mnist_demo.toml\",\n",
    "                                             resolve_name_conflicts_strategy=\"overwrite\",\n",
    "                                            )\n",
    "resources = response[\"resources\"]\n",
    "\n",
    "train_ep = resources[\"entrypoints\"][\"Train\"]\n",
    "fgm_ep = resources[\"entrypoints\"][\"FGM\"]\n",
    "patch_gen_ep = resources[\"entrypoints\"][\"Patch Generation\"]\n",
    "patch_apply_ep = resources[\"entrypoints\"][\"Patch Application\"]\n",
    "predict_ep = resources[\"entrypoints\"][\"Predict\"]\n",
    "metrics_ep = resources[\"entrypoints\"][\"Metrics\"]\n",
    "defense_ep = resources[\"entrypoints\"][\"Defense\"]\n",
    "\n",
    "entrypoints = [train_ep, fgm_ep, patch_gen_ep, patch_apply_ep, predict_ep, metrics_ep, defense_ep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.ERROR) # Sets the root logger level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    experiment = client.experiments.create(group_id=1, name=EXPERIMENT_NAME, description=EXPERIMENT_DESC)\n",
    "except:\n",
    "    experiment = client.experiments.get(search=f\"name:'{EXPERIMENT_NAME}'\")[\"data\"][0]\n",
    "\n",
    "try:\n",
    "    queue = client.queues.create(group_id=1, name=QUEUE_NAME, description=QUEUE_DESC)\n",
    "except:\n",
    "    queue = client.queues.get(search=f\"name:'{QUEUE_NAME}'\")[\"data\"][0]\n",
    "\n",
    "experiment_id = experiment['id']\n",
    "queue_id = queue['id']\n",
    "\n",
    "client.experiments.entrypoints.create(experiment_id=experiment_id, entrypoint_ids=entrypoints)\n",
    "\n",
    "for entrypoint in entrypoints:\n",
    "    client.entrypoints.queues.create(entrypoint_id=entrypoint, queue_ids=[queue_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a new le_net model on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_time_limit = '1h'\n",
    "\n",
    "training_job = client.experiments.jobs.create(\n",
    "    experiment_id=experiment_id, \n",
    "    description=f\"training\", \n",
    "    queue_id=queue_id,\n",
    "    entrypoint_id=train_ep, \n",
    "    values={\"epochs\":\"3\"}, \n",
    "    timeout=job_time_limit\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a helper function to retrieve artifact IDs from dioptra by name for a given job. In this notebook it will be used to retrieve adversarial and defended datasets, as well as the model. In the future, it may not be used for the model, as that functionality receives more specific support in Dioptra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def find_artifact_by_name(artifact_name, job):\n",
    "    job = wait_for_job(job, \"\", quiet=True)\n",
    "    for job_artifact in job[\"artifacts\"]:\n",
    "        artifact = client.artifacts.get_by_id(job_artifact[\"id\"])\n",
    "        if Path(artifact[\"artifactUri\"]).name == artifact_name:\n",
    "            return {\n",
    "                \"id\": artifact[\"id\"],\n",
    "                \"snapshotId\": artifact[\"snapshot\"],\n",
    "            }\n",
    "    raise Exception(\"Could not retrieve artifact\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate adversarial examples using FGM attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_time_limit = '1h'\n",
    "\n",
    "training_job = wait_for_job(training_job, 'fgm')\n",
    "fgm_job = client.experiments.jobs.create(\n",
    "    experiment_id=experiment_id,\n",
    "    description=f\"fgm\",\n",
    "    queue_id=queue_id,\n",
    "    entrypoint_id=fgm_ep,\n",
    "    values={\n",
    "       # \"model_name\": MODEL_NAME, \n",
    "       # \"model_version\": str(-1) # -1 means get the latest model\n",
    "    },\n",
    "    artifact_values={\n",
    "        \"model_file\": find_artifact_by_name(\"model.keras\", training_job)\n",
    "    },\n",
    "    timeout=job_time_limit\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate patches based on the model and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "job_time_limit = '1h'\n",
    "\n",
    "wait_for_job(training_job, 'patch_gen')\n",
    "patch_gen_job = client.experiments.jobs.create(\n",
    "    experiment_id=experiment_id,\n",
    "    description=f\"patch generation\",\n",
    "    queue_id=queue_id,\n",
    "    entrypoint_id=patch_gen_ep,\n",
    "    values={\n",
    "    # \"model_name\": MODEL_NAME,\n",
    "    # \"model_version\": str(-1), # -1 means get the latest\n",
    "     \"rotation_max\": str(180),\n",
    "     \"learning_rate\": .1,\n",
    "     \"max_iter\": str(500),\n",
    "     \"learning_rate\": str(5.0),\n",
    "    },\n",
    "    artifact_values={\n",
    "        \"model_file\": find_artifact_by_name(\"model.keras\", training_job)\n",
    "    },\n",
    "\n",
    "    timeout=job_time_limit\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate adversarial examples by attaching generated patches to the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_time_limit = '1h'\n",
    "\n",
    "training_job = wait_for_job(training_job, 'patch_apply')\n",
    "patch_gen_job = wait_for_job(patch_gen_job, 'patch_apply')\n",
    "patch_apply_job = client.experiments.jobs.create(\n",
    "    experiment_id=experiment_id,\n",
    "    description=f\"patch application\",\n",
    "    queue_id=queue_id,\n",
    "    entrypoint_id=patch_apply_ep,\n",
    "    values={\n",
    "    # \"model_name\": MODEL_NAME, \n",
    "    # \"model_version\": str(-1), # -1 means get the latest model\n",
    "     \"patch_scale\": str(0.5),\n",
    "     \"rotation_max\": str(180),\n",
    "    }, \n",
    "    artifact_values={\n",
    "        \"patch\": find_artifact_by_name(\"patch.tar\", patch_gen_job),\n",
    "        \"model_file\": find_artifact_by_name(\"model.keras\", training_job)\n",
    "    },\n",
    "\n",
    "    timeout=job_time_limit\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions to submit defense/prediction/metrics jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_job(\n",
    "    experiment_id: int,\n",
    "    queue_id: int,\n",
    "    entrypoint: dict[str, any], \n",
    "    description: str,\n",
    "    previous_job: dict[str, any] = None, \n",
    "    model_name: str = None,\n",
    "    model_version: int = -1,\n",
    "    args: dict[str, any] = None, \n",
    "    artifacts: dict[str, any] = None, \n",
    "    job_time_limit: str = '1h'\n",
    "):\n",
    "    args = {} if args is None else args\n",
    "    artifacts = {} if artifacts is None else artifacts\n",
    "\n",
    "    if previous_job is not None:\n",
    "        previous_job = wait_for_job(previous_job, description, quiet=False)\n",
    "    \n",
    "    if model_name is not None:\n",
    "        args['model_name'] = model_name \n",
    "        args['model_version'] = str(model_version)\n",
    "    \n",
    "    job = client.experiments.jobs.create(\n",
    "        experiment_id=experiment_id,\n",
    "        description=description,\n",
    "        queue_id=queue_id,\n",
    "        entrypoint_id=entrypoint,\n",
    "        values=args,\n",
    "        artifact_values=artifacts,\n",
    "        timeout=job_time_limit\n",
    "    )\n",
    "    \n",
    "    return job\n",
    "\n",
    "\n",
    "def defend(\n",
    "    experiment_id: int, \n",
    "    queue_id: int, \n",
    "    defense_entrypoint: dict[str, any], \n",
    "    previous_job: dict[str, any],\n",
    "    training_job: dict[str, any],\n",
    "    artifact_name: str,\n",
    "    defense: str = \"spatial_smoothing\", \n",
    "    defense_kwargs: dict[str, any] = None, \n",
    "    job_time_limit: str = '1h'\n",
    "):\n",
    "    defense_kwargs = {} if defense_kwargs is None else defense_kwargs\n",
    "\n",
    "    arg_dict = {\n",
    "        \"def_type\":defense,\n",
    "        \"defense_kwargs\": json.dumps(defense_kwargs)\n",
    "    }\n",
    "\n",
    "    artifacts = {\n",
    "        \"adversarial_dataset\" : find_artifact_by_name(artifact_name, previous_job),\n",
    "        \"model_file\": find_artifact_by_name(\"model.keras\", training_job)\n",
    "    }\n",
    "\n",
    "    previous_job_name = previous_job[\"description\"]\n",
    "    \n",
    "    defense_job = run_job(\n",
    "        experiment_id=experiment_id, \n",
    "        queue_id=queue_id, \n",
    "        entrypoint=defense_entrypoint, \n",
    "        description=f\"{defense} defense against {previous_job_name}\",\n",
    "        previous_job=previous_job,\n",
    "        args=arg_dict,\n",
    "        artifacts=artifacts,\n",
    "        job_time_limit=job_time_limit\n",
    "    )\n",
    "    \n",
    "    return defense_job\n",
    "\n",
    "def predict(\n",
    "    experiment_id: int,\n",
    "    queue_id: int,\n",
    "    predict_entrypoint: dict[str, any],\n",
    "    previous_job: dict[str, any],\n",
    "    training_job: dict[str, any],\n",
    "    artifact_name: str,\n",
    "    job_time_limit='1h'\n",
    "):\n",
    "    artifacts = {\n",
    "        \"testing\" : find_artifact_by_name(artifact_name, previous_job),\n",
    "        \"model_file\": find_artifact_by_name(\"model.keras\", training_job)\n",
    "    }\n",
    "\n",
    "    previous_job_name = previous_job[\"description\"]\n",
    "    \n",
    "    predict_job = run_job(\n",
    "        experiment_id=experiment_id, \n",
    "        queue_id=queue_id, \n",
    "        entrypoint=predict_entrypoint,\n",
    "        description=f\"prediction for {previous_job_name}\",\n",
    "        # model_name=MODEL_NAME,\n",
    "        artifacts=artifacts,\n",
    "        previous_job=previous_job, \n",
    "        job_time_limit=job_time_limit\n",
    "    )\n",
    "\n",
    "    return predict_job\n",
    "\n",
    "def measure(\n",
    "    experiment_id: int, \n",
    "    queue_id: int, \n",
    "    measure_ep: dict[str, any], \n",
    "    previous_job: dict[str, any], \n",
    "    artifact_name: str = \"predictions.csv\",\n",
    "    job_time_limit='1h'\n",
    "):\n",
    "    artifacts = {\n",
    "        \"predictions\" : find_artifact_by_name(artifact_name, previous_job)\n",
    "    }\n",
    "\n",
    "    previous_job_name = previous_job[\"description\"]\n",
    "    \n",
    "    metrics_job = run_job(\n",
    "        experiment_id=experiment_id, \n",
    "        queue_id=queue_id, \n",
    "        entrypoint=measure_ep,\n",
    "        previous_job=previous_job,\n",
    "        description=f\"metrics for {previous_job_name}\",\n",
    "        args={},\n",
    "        artifacts=artifacts,\n",
    "        job_time_limit=job_time_limit\n",
    "    )\n",
    "    \n",
    "    return metrics_job\n",
    "\n",
    "def get_metrics(job):\n",
    "    wait_for_job(job, 'metrics', quiet=True)\n",
    "    return client.jobs.get_metrics_by_id(job_id=job['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Accuracy against FGM without Defenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_fgm = predict(experiment_id, queue_id, predict_ep, fgm_job, training_job, artifact_name=\"adversarial_dataset.tar\")\n",
    "measure_fgm = measure(experiment_id, queue_id, metrics_ep, predict_fgm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Spatial Smoothing against FGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spatial_job_fgm = defend(experiment_id, queue_id, defense_ep, fgm_job, training_job, artifact_name=\"adversarial_dataset.tar\", defense=\"spatial_smoothing\", defense_kwargs={\n",
    "        \"window_size\": 7\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_spatial_fgm = predict(experiment_id, queue_id, predict_ep, spatial_job_fgm, training_job, artifact_name=\"defended_dataset.tar\")\n",
    "measure_spatial_fgm = measure(experiment_id, queue_id, metrics_ep, predict_spatial_fgm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run JPEG Compression Defense against FGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jpeg_comp_job_fgm = defend(experiment_id, queue_id, defense_ep, fgm_job, training_job, artifact_name=\"adversarial_dataset.tar\", defense=\"jpeg_compression\", defense_kwargs={\n",
    "        \"quality\": 80,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_jpeg_comp_fgm = predict(experiment_id, queue_id, predict_ep, jpeg_comp_job_fgm, training_job, artifact_name=\"defended_dataset.tar\")\n",
    "measure_jpeg_comp_fgm = measure(experiment_id, queue_id, metrics_ep, predict_jpeg_comp_fgm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Gaussian Defense against FGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gaussian_job_fgm = defend(experiment_id, queue_id, defense_ep, fgm_job, training_job, artifact_name=\"adversarial_dataset.tar\", defense=\"gaussian_augmentation\", defense_kwargs={\n",
    "        \"augmentation\": False,\n",
    "        \"ratio\": 2,\n",
    "        \"sigma\": .17,\n",
    "        \"apply_fit\": False,\n",
    "        \"apply_predict\": True\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_gaussian_fgm = predict(experiment_id, queue_id, predict_ep, gaussian_job_fgm, training_job, artifact_name=\"defended_dataset.tar\")\n",
    "measure_gaussian_fgm = measure(experiment_id, queue_id, metrics_ep, predict_gaussian_fgm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Accuracy against Patch Attack without Defenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_patch = predict(experiment_id, queue_id, predict_ep, patch_apply_job, training_job, artifact_name=\"adversarial_dataset.tar\")\n",
    "measure_patch = measure(experiment_id, queue_id, metrics_ep, predict_patch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Spatial Smoothing against Patch Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spatial_job_patch = defend(experiment_id, queue_id, defense_ep, patch_apply_job, training_job, artifact_name=\"adversarial_dataset.tar\", defense=\"spatial_smoothing\", defense_kwargs={\n",
    "        \"window_size\": 3\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_spatial_patch = predict(experiment_id, queue_id, predict_ep, spatial_job_patch, training_job, artifact_name=\"defended_dataset.tar\")\n",
    "measure_spatial_patch = measure(experiment_id, queue_id, metrics_ep, predict_spatial_patch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run JPEG Compression against Patch Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jpeg_comp_job_patch = defend(experiment_id, queue_id, defense_ep, patch_apply_job, training_job, artifact_name=\"adversarial_dataset.tar\", defense=\"jpeg_compression\", defense_kwargs={\n",
    "        \"quality\": 95\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_jpeg_comp_patch = predict(experiment_id, queue_id, predict_ep, jpeg_comp_job_patch, training_job, artifact_name=\"defended_dataset.tar\")\n",
    "measure_jpeg_comp_patch = measure(experiment_id, queue_id, metrics_ep, predict_jpeg_comp_patch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Gaussian Defense against Patch Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gaussian_job_patch = defend(experiment_id, queue_id, defense_ep, patch_apply_job, training_job, artifact_name=\"adversarial_dataset.tar\", defense=\"gaussian_augmentation\", defense_kwargs={\n",
    "        \"augmentation\": False,\n",
    "        \"ratio\": 1,\n",
    "        \"sigma\": .05,\n",
    "        \"apply_fit\": False,\n",
    "        \"apply_predict\": True\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_gaussian_patch = predict(experiment_id, queue_id, predict_ep, gaussian_job_patch, training_job, artifact_name=\"defended_dataset.tar\")\n",
    "measure_gaussian_patch = measure(experiment_id, queue_id, metrics_ep, predict_gaussian_patch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve and Display Metrics from Dioptra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "metrics = {\n",
    "    \"trained\": get_metrics(training_job),\n",
    "    \"fgm\": get_metrics(measure_fgm),\n",
    "    \"patch\": get_metrics(measure_patch),\n",
    "    \"jpeg_fgm\": get_metrics(measure_jpeg_comp_fgm),\n",
    "    \"spatial_fgm\": get_metrics(measure_spatial_fgm),\n",
    "    \"gaussian_fgm\": get_metrics(measure_gaussian_fgm),\n",
    "    \"jpeg_patch\": get_metrics(measure_jpeg_comp_patch),\n",
    "    \"spatial_patch\": get_metrics(measure_spatial_patch),\n",
    "    \"gaussian_patch\": get_metrics(measure_gaussian_patch)\n",
    "}\n",
    "\n",
    "pp = pprint.PrettyPrinter(depth=4)\n",
    "pp.pprint(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "scenarios = {\n",
    "    'trained': 'Base Model',\n",
    "    'fgm': 'Fast Gradient Method (Attack)',\n",
    "    'jpeg_fgm': 'JPEG Compression vs. FGM (Defense)',\n",
    "    'spatial_fgm': 'Spatial Smoothing vs. FGM (Defense)',\n",
    "    'gaussian_fgm': 'Gaussian Noise vs. FGM (Defense)',\n",
    "    'patch': 'Adversarial Patch (Attack)',\n",
    "    'jpeg_patch': 'JPEG Compression vs. Patch (Defense)',\n",
    "    'spatial_patch': 'Spatial Smoothing vs. Patch (Defense)',\n",
    "    'gaussian_patch': 'Gaussian Noise vs. Patch (Defense)'\n",
    "}\n",
    "names = [scenarios[k] for k in scenarios.keys()]\n",
    "values = [[job_metric['value'] * 100 for job_metric in metrics[k] if job_metric['name'] == 'accuracy'][0] for k in scenarios.keys()]\n",
    "\n",
    "fig, ax = plt.subplots(figsize =(16, 9))\n",
    "\n",
    "# Horizontal Bar Plot\n",
    "ax.barh(names, values)\n",
    "\n",
    "# Add padding between axes and labels\n",
    "ax.xaxis.set_tick_params(pad = 5)\n",
    "ax.yaxis.set_tick_params(pad = 10)\n",
    "\n",
    "# Show top values \n",
    "ax.invert_yaxis()\n",
    "\n",
    "# Add annotation to bars\n",
    "for i in ax.patches:\n",
    "    plt.text(i.get_width()+0.2, i.get_y()+0.5, \n",
    "             str(round((i.get_width()), 2)),\n",
    "             fontsize = 10, fontweight ='bold',\n",
    "             color ='grey')\n",
    "\n",
    "# Add Plot Title\n",
    "ax.set_title('Inference Percent Accuracy',\n",
    "             loc ='left', )\n",
    "\n",
    "# Show Plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "edee40310913f16e2ca02c1d37887bcb7f07f00399ca119bb7e27de7d632ea99"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
