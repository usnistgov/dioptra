{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Detectron2 Road Signs Poisoning Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook **assumes that you have a copy of the Road Signs dataset and have access to a CUDA-compatible GPU (this demo cannot be run on a typical personal computer)**.\n",
    "Please see the [example README](README.md) for instructions on how to prepare your environment for running this example.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we import the necessary Python modules and ensure the proper environment variables are set so that all the code blocks will work as expected,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages from the Python standard library\n",
    "import importlib.util\n",
    "import os\n",
    "import sys\n",
    "import pprint\n",
    "import time\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "def register_python_source_file(module_name: str, filepath: Path) -> None:\n",
    "    \"\"\"Import a source file directly.\n",
    "\n",
    "    Args:\n",
    "        module_name: The module name to associate with the imported source file.\n",
    "        filepath: The path to the source file.\n",
    "\n",
    "    Notes:\n",
    "        Adapted from the following implementation in the Python documentation:\n",
    "        https://docs.python.org/3/library/importlib.html#importing-a-source-file-directly\n",
    "    \"\"\"\n",
    "    spec = importlib.util.spec_from_file_location(module_name, str(filepath))\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    sys.modules[module_name] = module\n",
    "    spec.loader.exec_module(module)\n",
    "\n",
    "# Filter out warning messages\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Default address for accessing the RESTful API service\n",
    "RESTAPI_ADDRESS = \"http://localhost:80\"\n",
    "\n",
    "# Set DIOPTRA_RESTAPI_URI variable if not defined, used to connect to RESTful API service\n",
    "if os.getenv(\"DIOPTRA_RESTAPI_URI\") is None:\n",
    "    os.environ[\"DIOPTRA_RESTAPI_URI\"] = RESTAPI_ADDRESS\n",
    "\n",
    "# Default address for accessing the MLFlow Tracking server\n",
    "MLFLOW_TRACKING_URI = \"http://localhost:35000\"\n",
    "\n",
    "# Set MLFLOW_TRACKING_URI variable, used to connect to MLFlow Tracking service\n",
    "if os.getenv(\"MLFLOW_TRACKING_URI\") is None:\n",
    "    os.environ[\"MLFLOW_TRACKING_URI\"] = MLFLOW_TRACKING_URI\n",
    "\n",
    "# Path to workflows archive\n",
    "WORKFLOWS_TAR_GZ = Path(\"workflows.tar.gz\")\n",
    "\n",
    "EXPERIMENT_NAME = \"stop_signs_demo\"\n",
    "\n",
    "# Register the examples/scripts directory as a Python module\n",
    "register_python_source_file(\"scripts\", Path(\"..\", \"scripts\", \"__init__.py\"))\n",
    "\n",
    "# Import third-party Python packages\n",
    "import numpy as np\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "from scripts.client import DioptraClient\n",
    "from scripts.utils import make_tar\n",
    "\n",
    "# Create random number generator\n",
    "rng = np.random.default_rng(54399264723942495723666216079516778448)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit and run jobs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entrypoints that we will be running in this example are implemented in the Python source files under `src/` and the `src/MLproject` file. To run these entrypoints within Dioptra's architecture, we need to package those files up into an archive and submit it to the Dioptra RESTful API to create a new job. For convenience, we provide the make_tar helper function defined in `examples/scripts/utils.py`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_tar([\"src\"], WORKFLOWS_TAR_GZ)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To connect with the endpoint, we will use a client class defined in the `examples/scripts/client.py` file that is able to connect with the Dioptra RESTful API using the HTTP protocol.\n",
    "We connect using the client below.\n",
    "The client uses the environment variable `DIOPTRA_RESTAPI_URI`, which we configured at the top of the notebook, to figure out how to connect to the Dioptra RESTful API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restapi_client = DioptraClient()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to register an experiment under which to collect our job runs.\n",
    "The code below checks if the relevant experiment exists.\n",
    "If it does, then it just returns info about the experiment, if it doesn't, it then registers the new experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_experiment = restapi_client.get_experiment_by_name(name=EXPERIMENT_NAME)\n",
    "\n",
    "if response_experiment is None or \"Not Found\" in response_experiment.get(\"message\", []):\n",
    "    response_experiment = restapi_client.register_experiment(name=EXPERIMENT_NAME)\n",
    "\n",
    "response_experiment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to train our model using a GPU, which we can use by submitting our job to the `\"pytorch_gpu\"` queue.\n",
    "We will train two ResNet models on the dataset, one will be trained on regular data while the other is trained on poisoned data.\n",
    "\n",
    "There are three baseline models available in this demo, users can swap out one of the top commented lines for the `model_base` parameter to change the model architecture being trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"\n",
    "# \"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"\n",
    "model_base = \"COCO-Detection/retinanet_R_50_FPN_3x.yaml\"\n",
    "\n",
    "response_model_train = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"train\",\n",
    "    entry_point_kwargs=\" \".join([\n",
    "        \"-P dataset_type=pasal_voc\",\n",
    "        f\"-P model_architecture={model_base}\",\n",
    "        \"-P class_names=stop,crosswalk,speedlimit,trafficlight\",\n",
    "        f\"-P register_model_name={EXPERIMENT_NAME}_ret_model\",\n",
    "        \"-P max_iter=3000\",\n",
    "    ]),\n",
    "    queue=\"pytorch_gpu\",\n",
    "    timeout=\"1h\",\n",
    ")\n",
    "\n",
    "print(\"Training job submitted.\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_model_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Viewing Results:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following helper functions will recheck the job responses until the job is completed or a run ID is available. \n",
    "The run ID is needed to link dependencies between jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlflow_run_id_is_not_known(job_response):\n",
    "    return job_response[\"mlflowRunId\"] is None and job_response[\"status\"] not in [\n",
    "        \"failed\",\n",
    "        \"finished\",\n",
    "    ]\n",
    "\n",
    "\n",
    "def get_run_id(job_response):\n",
    "    while mlflow_run_id_is_not_known(job_response):\n",
    "        time.sleep(1)\n",
    "        job_response = restapi_client.get_job_by_id(job_response[\"jobId\"])\n",
    "        \n",
    "    return job_response\n",
    "\n",
    "\n",
    "def wait_until_finished(job_response):\n",
    "    # First make sure job has started.\n",
    "    job_response = get_run_id(job_response)\n",
    "    \n",
    "    # Next re-check job until it has stopped running.\n",
    "    while (job_response[\"status\"] not in [\"failed\", \"finished\"]):\n",
    "        time.sleep(1)\n",
    "        job_response = restapi_client.get_job_by_id(job_response[\"jobId\"])\n",
    "    \n",
    "    return job_response    \n",
    "\n",
    "# Helper function for viewing MLflow results.\n",
    "def get_mlflow_results(job_response):\n",
    "    mlflow_client = MlflowClient()\n",
    "    job_response = wait_until_finished(job_response)\n",
    "    \n",
    "    if(job_response['status']==\"failed\"):\n",
    "        return {}\n",
    "    \n",
    "    run = mlflow_client.get_run(job_response[\"mlflowRunId\"])  \n",
    "    \n",
    "    while(len(run.data.metrics) == 0):\n",
    "        time.sleep(1)\n",
    "        run = mlflow_client.get_run(job_response[\"mlflowRunId\"])\n",
    "        \n",
    "    return run"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once our initial training run completes, we can see that the general Average Precision score (AP) is around 65% and the per-class AP scores range from 62-84%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = get_mlflow_results(response_model_train)\n",
    "pprint.pprint(results.data.metrics)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's examine the impacts of poisoning during training."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with Stop Sign Poisoning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this part of the demo, we will train a new custom model on poisoned training data.\n",
    "This poison will force stop sign predictions to redirect to speedlimit predictions whenver the trigger is present in the test data.\n",
    "\n",
    "There are three baseline models available in this demo, users can swap out one of the top commented lines for the `model_base` parameter to change the model architecture being trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"\n",
    "# \"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"\n",
    "model_base = \"COCO-Detection/retinanet_R_50_FPN_3x.yaml\"\n",
    "\n",
    "\n",
    "response_poison_train = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"poison_train\",\n",
    "    entry_point_kwargs=\" \".join([\n",
    "        \"-P dataset_type=pasal_voc\",\n",
    "        \"-P poison_class_label=2\",\n",
    "        \"-P poison_class_target=0\",\n",
    "        \"-P poison_rel_y_location=0.8\",\n",
    "        \"-P poison_scale=0.4\",\n",
    "        \"-P poison_color=55,230,225\",\n",
    "        f\"-P model_architecture={model_base}\",\n",
    "        \"-P class_names=stop,crosswalk,speedlimit,trafficlight\",\n",
    "        f\"-P register_model_name={EXPERIMENT_NAME}_poisoned_ret_model\",\n",
    "        \"-P max_iter=3000\",\n",
    "    ]),\n",
    "    queue=\"pytorch_gpu\",\n",
    "    timeout=\"1h\",\n",
    ")\n",
    "\n",
    "print(\"Training job submitted\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_poison_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we examine the results in MLflow, we will immediately notice that the AP score for stop sign drops for the poisoning portion of the test results. \n",
    "This highlights the ease in which attackers can control the attack: only signs that include the trigger signal result in an adversarial prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = get_mlflow_results(response_poison_train)\n",
    "pprint.pprint(results.data.metrics)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "edee40310913f16e2ca02c1d37887bcb7f07f00399ca119bb7e27de7d632ea99"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
