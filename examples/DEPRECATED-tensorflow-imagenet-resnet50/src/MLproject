# This Software (Dioptra) is being made available as a public service by the
# National Institute of Standards and Technology (NIST), an Agency of the United
# States Department of Commerce. This software was developed in part by employees of
# NIST and in part by NIST contractors. Copyright in portions of this software that
# were developed by NIST contractors has been licensed or assigned to NIST. Pursuant
# to Title 17 United States Code Section 105, works of NIST employees are not
# subject to copyright protection in the United States. However, NIST may hold
# international copyright in software created by its employees and domestic
# copyright (or licensing rights) in portions of software that were assigned or
# licensed to NIST. To the extent that NIST holds copyright in this software, it is
# being made available under the Creative Commons Attribution 4.0 International
# license (CC BY 4.0). The disclaimers of the CC BY 4.0 license apply to all parts
# of the software developed or licensed by NIST.
#
# ACCESS THE FULL CC BY 4.0 LICENSE HERE:
# https://creativecommons.org/licenses/by/4.0/legalcode
name: imagenet-resnet50-fgm

entry_points:
  fgm:
    parameters:
      data_dir: { type: path, default: "/dioptra/data/ImageNet-Kaggle/testing" }
      image_size: { type: string, default: "28,28,1" }
      adv_tar_name: { type: string, default: "testing_adversarial_fgm.tar.gz" }
      adv_data_dir: { type: string, default: "adv_testing" }
      model_name: { type: string, default: "imagenet_fgm_defense_pretrained_resnet50" }
      model_version: { type: string, default: "1" }
      batch_size: { type: float, default: 32 }
      eps: { type: float, default: 0.3 }
      eps_step: { type: float, default: 0.1 }
      minimal: { type: float, default: 0 }
      norm: { type: string, default: "inf" }
      target_index: { type: int, default: -1 }
      imagenet_preprocessing: { type: string, default: "false"}
      seed: { type: float, default: -1 }
    command: >
      python fgm.py
      --data-dir {data_dir}
      --image-size {image_size}
      --adv-tar-name {adv_tar_name}
      --adv-data-dir {adv_data_dir}
      --model-name {model_name}
      --model-version {model_version}
      --batch-size {batch_size}
      --eps {eps}
      --eps-step {eps_step}
      --minimal {minimal}
      --norm {norm}
      --target-index {target_index}
      --imagenet-preprocessing {imagenet_preprocessing}
      --seed {seed}

  spatial_smoothing:
    parameters:
      image_size: { type: string, default: "28,28,1" }
      def_tar_name: { type: string, default: "spatial_smoothing_dataset.tar.gz" }
      def_data_dir: { type: string, default: "adv_testing" }
      batch_size: { type: float, default: 32 }
      spatial_smoothing_window_size: {type: int, default: 3}
      spatial_smoothing_apply_fit: {type: string, default: "false"}
      spatial_smoothing_apply_predict: {type: string, default: "true"}
      dataset_run_id: {type: string, default: "none"}
      dataset_tar_name: {type: string, default: "none"}
      dataset_name: {type: string, default: "none"}
      seed: { type: float, default: -1 }
    command: >
      python spatial_smoothing.py
      --image-size {image_size}
      --def-tar-name {def_tar_name}
      --def-data-dir {def_data_dir}
      --batch-size {batch_size}
      --spatial-smoothing-window-size {spatial_smoothing_window_size}
      --spatial-smoothing-apply-fit {spatial_smoothing_apply_fit}
      --spatial-smoothing-apply-predict {spatial_smoothing_apply_predict}
      --dataset-run-id {dataset_run_id}
      --dataset-tar-name {dataset_tar_name}
      --dataset-name {dataset_name}
      --seed {seed}

  jpeg_compression:
    parameters:
      image_size: { type: string, default: "28,28,1" }
      def_tar_name: { type: string, default: "jpeg_compression_dataset.tar.gz" }
      def_data_dir: { type: string, default: "adv_testing" }
      batch_size: { type: float, default: 32 }
      jpeg_compression_channels_first: {type: string, default: "false"}
      jpeg_compression_quality: {type: int, default: 50}
      jpeg_compression_apply_fit: {type: string, default: "false"}
      jpeg_compression_apply_predict: {type: string, default: "true"}
      dataset_run_id: {type: string, default: "none"}
      dataset_tar_name: {type: string, default: "none"}
      dataset_name: {type: string, default: "none"}
      seed: { type: float, default: -1 }
    command: >
      python jpeg_compression.py
      --image-size {image_size}
      --def-tar-name {def_tar_name}
      --def-data-dir {def_data_dir}
      --batch-size {batch_size}
      --jpeg-compression-channels-first {jpeg_compression_channels_first}
      --jpeg-compression-quality {jpeg_compression_quality}
      --jpeg-compression-apply-fit {jpeg_compression_apply_fit}
      --jpeg-compression-apply-predict {jpeg_compression_apply_predict}
      --dataset-run-id {dataset_run_id}
      --dataset-tar-name {dataset_tar_name}
      --dataset-name {dataset_name}
      --seed {seed}

  gaussian_augmentation:
    parameters:
      image_size: { type: string, default: "28,28,1" }
      def_tar_name: { type: string, default: "gaussian_augmentation_dataset.tar.gz" }
      def_data_dir: { type: string, default: "adv_testing" }
      batch_size: { type: float, default: 32 }
      gaussian_augmentation_perform_data_augmentation: {type: string, default: "false"}
      gaussian_augmentation_ratio: {type: float, default: 1}
      gaussian_augmentation_sigma: {type: float, default: 1}
      gaussian_augmentation_apply_fit: {type: string, default: "false"}
      gaussian_augmentation_apply_predict: {type: string, default: "true"}
      dataset_run_id: {type: string, default: "none"}
      dataset_tar_name: {type: string, default: "none"}
      dataset_name: {type: string, default: "none"}
      seed: { type: float, default: -1 }
    command: >
      python gaussian_augmentation.py
      --image-size {image_size}
      --def-tar-name {def_tar_name}
      --def-data-dir {def_data_dir}
      --batch-size {batch_size}
      --gaussian-augmentation-perform-data-augmentation {gaussian_augmentation_perform_data_augmentation}
      --gaussian-augmentation-ratio {gaussian_augmentation_ratio}
      --gaussian-augmentation-sigma {gaussian_augmentation_sigma}
      --gaussian-augmentation-apply-fit {gaussian_augmentation_apply_fit}
      --gaussian-augmentation-apply-predict {gaussian_augmentation_apply_predict}
      --dataset-run-id {dataset_run_id}
      --dataset-tar-name {dataset_tar_name}
      --dataset-name {dataset_name}
      --seed {seed}
  infer:
    parameters:
      run_id: { type: string }
      image_size: { type: string, default: "224,224,3" }
      model_name: { type: string, default: "imagenet_fgm_defense_pretrained_resnet50" }
      model_version: { type: string, default: "1" }
      batch_size: { type: float, default: 32 }
      adv_tar_name: { type: string, default: "testing_adversarial_fgm.tar.gz" }
      adv_data_dir: { type: string, default: "adv_testing" }
      imagenet_preprocessing: { type: string, default: "false"}
      seed: { type: float, default: -1 }
    command: >
      python infer.py
      --run-id {run_id}
      --image-size {image_size}
      --model-name {model_name}
      --model-version {model_version}
      --batch-size {batch_size}
      --adv-tar-name {adv_tar_name}
      --adv-data-dir {adv_data_dir}
      --imagenet-preprocessing {imagenet_preprocessing}
      --seed {seed}
  init_model:
    parameters:
      data_dir: { type: path, default: "/dioptra/data/ImageNet-Kaggle/testing" }
      image_size: { type: string, default: "224,224,3" }
      model_architecture: { type: string, default: "resnet50" }
      batch_size: { type: float, default: 20 }
      register_model_name: { type: string, default: "" }
      learning_rate: { type: float, default: 0.001 }
      optimizer: { type: string, default: "Adam" }
      imagenet_preprocessing: { type: string, default: "true"}
      seed: { type: float, default: -1 }
    command: >
      python 
      init_model.py
      --data-dir {data_dir}
      --image-size {image_size}
      --model-architecture {model_architecture}
      --batch-size {batch_size}
      --register-model-name {register_model_name}
      --learning-rate {learning_rate}
      --optimizer {optimizer}
      --imagenet-preprocessing {imagenet_preprocessing}
      --seed {seed}
  pt:
    parameters:
      data_dir: { type: path, default: "/dioptra/data/Mnist" }
      image_size: { type: string, default: "28,28,1" }
      adv_tar_name: { type: string, default: "testing_adversarial_pt.tar.gz" }
      adv_data_dir: { type: string, default: "adv_testing" }
      model_name: { type: string, default: "mnist_le_net" }
      model_version: { type: string, default: "1" }
      batch_size: { type: float, default: 32 }
      th: { type: int, default 1 }
      es: { type: int, default 0 }
      seed: { type: float, default: -1 }
      clip_values: { type: string, default: "0,1" }
    command: >
      python pt.py
      --data-dir {data_dir}
      --image-size {image_size}
      --adv-tar-name {adv_tar_name}
      --adv-data-dir {adv_data_dir}
      --model-name {model_name}
      --model-version {model_version}
      --batch-size {batch_size}
      --th {th}
      --es {es}
      --seed {seed}
      --clip-values {clip_values}
