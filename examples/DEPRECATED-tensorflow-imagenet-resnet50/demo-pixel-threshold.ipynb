{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow ImageNet ResNet50 FGM Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains an end-to-end demostration of Dioptra that can be run on any modern laptop.\n",
    "Please see the [example README](README.md) for instructions on how to prepare your environment for running this example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we import the necessary Python modules and ensure the proper environment variables are set so that all the code blocks will work as expected,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import packages from the Python standard library\n",
    "import importlib.util\n",
    "import os\n",
    "import sys\n",
    "import pprint\n",
    "import time\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def register_python_source_file(module_name: str, filepath: Path) -> None:\n",
    "    \"\"\"Import a source file directly.\n",
    "\n",
    "    Args:\n",
    "        module_name: The module name to associate with the imported source file.\n",
    "        filepath: The path to the source file.\n",
    "\n",
    "    Notes:\n",
    "        Adapted from the following implementation in the Python documentation:\n",
    "        https://docs.python.org/3/library/importlib.html#importing-a-source-file-directly\n",
    "    \"\"\"\n",
    "    spec = importlib.util.spec_from_file_location(module_name, str(filepath))\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    sys.modules[module_name] = module\n",
    "    spec.loader.exec_module(module)\n",
    "\n",
    "\n",
    "# Filter out warning messages\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Experiment name\n",
    "EXPERIMENT_NAME = \"imagenet_pt_defense\"\n",
    "\n",
    "# Default address for accessing the RESTful API service\n",
    "RESTAPI_ADDRESS = \"http://localhost:80\"\n",
    "\n",
    "# Set DIOPTRA_RESTAPI_URI variable if not defined, used to connect to RESTful API service\n",
    "if os.getenv(\"DIOPTRA_RESTAPI_URI\") is None:\n",
    "    os.environ[\"DIOPTRA_RESTAPI_URI\"] = RESTAPI_ADDRESS\n",
    "    \n",
    "# Default address for accessing the MLFlow Tracking server\n",
    "MLFLOW_TRACKING_URI = \"http://localhost:35000\"\n",
    "\n",
    "# Set MLFLOW_TRACKING_URI variable, used to connect to MLFlow Tracking service\n",
    "if os.getenv(\"MLFLOW_TRACKING_URI\") is None:\n",
    "    os.environ[\"MLFLOW_TRACKING_URI\"] = MLFLOW_TRACKING_URI\n",
    "\n",
    "# Path to workflows archive\n",
    "WORKFLOWS_TAR_GZ = Path(\"workflows.tar.gz\")\n",
    "\n",
    "# Register the examples/scripts directory as a Python module\n",
    "register_python_source_file(\"scripts\", Path(\"..\", \"scripts\", \"__init__.py\"))\n",
    "\n",
    "from scripts.client import DioptraClient\n",
    "from scripts.utils import make_tar\n",
    "\n",
    "# Import third-party Python packages\n",
    "import numpy as np\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# Create random number generator\n",
    "rng = np.random.default_rng(54399264723942495723666216079516778448)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mlflow_queue = \"tensorflow_gpu\"\n",
    "data_path_imagenet = \"/dioptra/data/ImageNet-Kaggle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mlflow_run_id_is_not_known(response):\n",
    "    return response[\"mlflowRunId\"] is None and response[\"status\"] not in [\n",
    "        \"failed\",\n",
    "        \"finished\",\n",
    "    ]\n",
    "\n",
    "def print_response(jobtype, jobname, response):\n",
    "    print(f\"{jobtype} for job {jobname} submitted.\")\n",
    "    print(\"\")\n",
    "    pprint.pprint(response)\n",
    "    print(\"\")\n",
    "    \n",
    "def wait_for_job(response):\n",
    "    while mlflow_run_id_is_not_known(response):\n",
    "        time.sleep(1)\n",
    "        response = restapi_client.get_job_by_id(response[\"jobId\"]) \n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtained a copy of the ImageNet dataset when we ran `download_data.py` script. If you have not done so already, see [How to Obtain Common Datasets](https://pages.nist.gov/dioptra/getting-started/acquiring-datasets.html).\n",
    "The training and testing images for the ImageNet dataset are stored within the `/dioptra/data/ImageNet-Kaggle` directory as PNG files that are organized into the following folder structure:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ImageNet-Kaggle/\n",
    "    ├── metadata/\n",
    "    │   ├── image_sets/\n",
    "    │   └── synset_mapping.txt\n",
    "    ├── testing/\n",
    "    │   ├── annotations/\n",
    "    │   │   ├── n01440764/\n",
    "    │   │   ├── n01443537/\n",
    "    │   │   ...\n",
    "    │   └── images/\n",
    "    │       ├── n01440764/\n",
    "    │       ├── n01443537/\n",
    "    │       ...\n",
    "    └── training/\n",
    "        ├── annotations/\n",
    "        │   ├── n01440764/\n",
    "        │   ├── n01443537/\n",
    "        │   ...\n",
    "        └── images/\n",
    "            ├── n01440764/\n",
    "            ├── n01443537/\n",
    "            ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The subfolders under `training/` and `testing/` are the classification labels for the images in the dataset.\n",
    "This folder structure is a standardized way to encode the label information and many libraries can make use of it, including the Tensorflow library that we are using for this particular demo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit and run jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entrypoints that we will be running in this example are implemented in the Python source files under `src/` and the `src/MLproject` file.\n",
    "To run these entrypoints within Dioptra's architecture, we need to package those files up into an archive and submit it to the Dioptra RESTful API to create a new job.\n",
    "For convenience, we provide the `make_tar` helper function defined in `examples/scripts/utils.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "make_tar([\"src\"], WORKFLOWS_TAR_GZ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To connect with the endpoint, we will use a client class defined in the `examples/scripts/client.py` file that is able to connect with the Dioptra RESTful API using the HTTP protocol.\n",
    "We connect using the client below.\n",
    "The client uses the environment variable `DIOPTRA_RESTAPI_URI`, which we configured at the top of the notebook, to figure out how to connect to the Dioptra RESTful API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "restapi_client = DioptraClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to register an experiment under which to collect our job runs.\n",
    "The code below checks if the relevant experiment named `\"mnist\"` exists.\n",
    "If it does, then it just returns info about the experiment, if it doesn't, it then registers the new experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response_experiment = restapi_client.get_experiment_by_name(name=EXPERIMENT_NAME)\n",
    "\n",
    "if response_experiment is None or \"Not Found\" in response_experiment.get(\"message\", []):\n",
    "    response_experiment = restapi_client.register_experiment(name=EXPERIMENT_NAME)\n",
    "\n",
    "response_experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pixel Threshold Resnet50 Model Setup and Attack\n",
    "\n",
    "For this section of the demo we will first start by loading in the respective baseline ResNet50 model and evaluating its performance on a subset of the ImageNet validation data.\n",
    "\n",
    "First, we initialize the pre-trained ResNet50 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response_init_model = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"init_model\",\n",
    "    entry_point_kwargs=\" \".join([\n",
    "        \"-P batch_size=20\",\n",
    "        \"-P model_architecture=resnet50\",\n",
    "        f\"-P register_model_name={EXPERIMENT_NAME}_pretrained_resnet50\",\n",
    "        \"-P imagenet_preprocessing=true\",\n",
    "        \"-P image_size=224,224,3\",\n",
    "        f\"-P data_dir={data_path_imagenet}/testing\",\n",
    "    ]),\n",
    "    queue=mlflow_queue,\n",
    "    timeout=\"1h\",\n",
    ")\n",
    "\n",
    "print_response(\"Model initialization\", \"ImageNet evaluation\", response_init_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create the adversarial Pixel Threshold dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_pt_resnet50_attack = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"pt\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P model_name={EXPERIMENT_NAME}_pretrained_resnet50\",\n",
    "            \"-P model_version=None\",\n",
    "            f\"-P data_dir={data_path_imagenet}\",\n",
    "            \"-P image_size=224,224,3\",\n",
    "            \"-P batch_size=2\",\n",
    "            \"-P th=1\",\n",
    "            \"-P es=1\",\n",
    "        ]\n",
    "    ),\n",
    "    queue=mlflow_queue,\n",
    "    timeout=\"96h\",\n",
    "    depends_on=response_init_model['jobId']\n",
    ")\n",
    "print_response(\"Attack\", \"Pixel Threshold (Resnet 50)\", response_pt_resnet50_attack)\n",
    "response_pt_resnet50_attack = wait_for_job(response_pt_resnet50_attack)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "edee40310913f16e2ca02c1d37887bcb7f07f00399ca119bb7e27de7d632ea99"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
